{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"mount_file_id":"1GrN8-Qd6Gyktq0wnK_-sRKoB0DhVFLcQ","authorship_tag":"ABX9TyNmQ6H64EFYYrseEpPekQCP"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"widgets":{"application/vnd.jupyter.widget-state+json":{"7c743c61c32348508ba8f62d77a5d0b7":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_b429e755ee4f43fc80044933c5711036","IPY_MODEL_f00c0fd2b50d4cea9bb9af80eb96b654","IPY_MODEL_810590de6d604661943398ca8b2f5b05"],"layout":"IPY_MODEL_3b578e9d0d0845b8946d0e6168497a18"}},"b429e755ee4f43fc80044933c5711036":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_f4175bb8705c43f8b3ed22ca53c711ae","placeholder":"​","style":"IPY_MODEL_44b49fc091204131997449fcc04ee1ba","value":"Downloading (…)ve/main/spiece.model: 100%"}},"f00c0fd2b50d4cea9bb9af80eb96b654":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_bb1f1723bdb1471c83098a88ee145bf3","max":798011,"min":0,"orientation":"horizontal","style":"IPY_MODEL_1ee4943de22a479693709f8c7aa1439b","value":798011}},"810590de6d604661943398ca8b2f5b05":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_7aca70bb0d05441c872b05a4d6e139c9","placeholder":"​","style":"IPY_MODEL_0ed59e03144a456688bca1607c9d992d","value":" 798k/798k [00:00&lt;00:00, 14.1MB/s]"}},"3b578e9d0d0845b8946d0e6168497a18":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"f4175bb8705c43f8b3ed22ca53c711ae":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"44b49fc091204131997449fcc04ee1ba":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"bb1f1723bdb1471c83098a88ee145bf3":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"1ee4943de22a479693709f8c7aa1439b":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"7aca70bb0d05441c872b05a4d6e139c9":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"0ed59e03144a456688bca1607c9d992d":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"5ed9dea6dac94ce9ba9207e74ee38efd":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_d347ee29ce61455392e994fe8d8db53d","IPY_MODEL_7a1bfe94867a4d97ad06e37eda64d1ee","IPY_MODEL_a06b1ec0a9064b0e9e24bab6457e05c2"],"layout":"IPY_MODEL_1a561be590f4498f8f77d8fbbe400a69"}},"d347ee29ce61455392e994fe8d8db53d":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_6b371f3e2fa44008b82fa8a084e87a9b","placeholder":"​","style":"IPY_MODEL_952e2bb1afb645d991acdfad42e1fe1d","value":"Downloading (…)lve/main/config.json: 100%"}},"7a1bfe94867a4d97ad06e37eda64d1ee":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_f174e3fd04354ed085718febba12b385","max":760,"min":0,"orientation":"horizontal","style":"IPY_MODEL_85c4b8f301354b8eaeb91015aac4c709","value":760}},"a06b1ec0a9064b0e9e24bab6457e05c2":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_2fa2e2d8b4fd450c8b033f4d75056399","placeholder":"​","style":"IPY_MODEL_10c71733774e4954a6a4d8109bb7ebdc","value":" 760/760 [00:00&lt;00:00, 43.7kB/s]"}},"1a561be590f4498f8f77d8fbbe400a69":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"6b371f3e2fa44008b82fa8a084e87a9b":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"952e2bb1afb645d991acdfad42e1fe1d":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"f174e3fd04354ed085718febba12b385":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"85c4b8f301354b8eaeb91015aac4c709":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"2fa2e2d8b4fd450c8b033f4d75056399":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"10c71733774e4954a6a4d8109bb7ebdc":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"5ef9830ab2034226b38e4a9242977533":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_5a3c365627c0469b90b956fa0ee5f718","IPY_MODEL_9a19988d574045529bffebdca851f13c","IPY_MODEL_4b7fc98869834347a9844b57dcee26b2"],"layout":"IPY_MODEL_80ca5d19a28e4a059bdacdf5261ba4f0"}},"5a3c365627c0469b90b956fa0ee5f718":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_9fe132d9dbb94e5c9a65340a17f8ac4c","placeholder":"​","style":"IPY_MODEL_541bd0b6c0f74201b3fef130ffcfe642","value":"Downloading pytorch_model.bin: 100%"}},"9a19988d574045529bffebdca851f13c":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_38c8bc8659a64ddb9df43730a4ae1ffa","max":467042463,"min":0,"orientation":"horizontal","style":"IPY_MODEL_d0ff1a0534554aeea9f3b60873c47078","value":467042463}},"4b7fc98869834347a9844b57dcee26b2":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_d64abb8ce2674fc39b80e06dd261d4e4","placeholder":"​","style":"IPY_MODEL_6a35ed4ff7c94a0895143f2ec5646dec","value":" 467M/467M [00:01&lt;00:00, 341MB/s]"}},"80ca5d19a28e4a059bdacdf5261ba4f0":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"9fe132d9dbb94e5c9a65340a17f8ac4c":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"541bd0b6c0f74201b3fef130ffcfe642":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"38c8bc8659a64ddb9df43730a4ae1ffa":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"d0ff1a0534554aeea9f3b60873c47078":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"d64abb8ce2674fc39b80e06dd261d4e4":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"6a35ed4ff7c94a0895143f2ec5646dec":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}}}}},"cells":[{"cell_type":"code","source":["!pip install transformers\n","!pip install sentencepiece\n","!pip install tensorflow_addons"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"cFdkfHWWMjTq","executionInfo":{"status":"ok","timestamp":1687321504223,"user_tz":-330,"elapsed":19760,"user":{"displayName":"Vedant Palit","userId":"05232341091904350034"}},"outputId":"1998a5e1-cdf5-431f-9e4f-6f84f570a7c6"},"execution_count":2,"outputs":[{"output_type":"stream","name":"stdout","text":["Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Collecting transformers\n","  Downloading transformers-4.30.2-py3-none-any.whl (7.2 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.2/7.2 MB\u001b[0m \u001b[31m111.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers) (3.12.0)\n","Collecting huggingface-hub<1.0,>=0.14.1 (from transformers)\n","  Downloading huggingface_hub-0.15.1-py3-none-any.whl (236 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m236.8/236.8 kB\u001b[0m \u001b[31m27.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (1.22.4)\n","Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers) (23.1)\n","Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (6.0)\n","Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (2022.10.31)\n","Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers) (2.27.1)\n","Collecting tokenizers!=0.11.3,<0.14,>=0.11.1 (from transformers)\n","  Downloading tokenizers-0.13.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (7.8 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.8/7.8 MB\u001b[0m \u001b[31m118.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting safetensors>=0.3.1 (from transformers)\n","  Downloading safetensors-0.3.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.3 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m78.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from transformers) (4.65.0)\n","Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.14.1->transformers) (2023.4.0)\n","Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.14.1->transformers) (4.5.0)\n","Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (1.26.15)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2022.12.7)\n","Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2.0.12)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.4)\n","Installing collected packages: tokenizers, safetensors, huggingface-hub, transformers\n","Successfully installed huggingface-hub-0.15.1 safetensors-0.3.1 tokenizers-0.13.3 transformers-4.30.2\n","Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Collecting sentencepiece\n","  Downloading sentencepiece-0.1.99-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.3 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m56.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hInstalling collected packages: sentencepiece\n","Successfully installed sentencepiece-0.1.99\n","Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Collecting tensorflow_addons\n","  Downloading tensorflow_addons-0.20.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (591 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m591.0/591.0 kB\u001b[0m \u001b[31m40.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from tensorflow_addons) (23.1)\n","Collecting typeguard<3.0.0,>=2.7 (from tensorflow_addons)\n","  Downloading typeguard-2.13.3-py3-none-any.whl (17 kB)\n","Installing collected packages: typeguard, tensorflow_addons\n","Successfully installed tensorflow_addons-0.20.0 typeguard-2.13.3\n"]}]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":220,"referenced_widgets":["7c743c61c32348508ba8f62d77a5d0b7","b429e755ee4f43fc80044933c5711036","f00c0fd2b50d4cea9bb9af80eb96b654","810590de6d604661943398ca8b2f5b05","3b578e9d0d0845b8946d0e6168497a18","f4175bb8705c43f8b3ed22ca53c711ae","44b49fc091204131997449fcc04ee1ba","bb1f1723bdb1471c83098a88ee145bf3","1ee4943de22a479693709f8c7aa1439b","7aca70bb0d05441c872b05a4d6e139c9","0ed59e03144a456688bca1607c9d992d","5ed9dea6dac94ce9ba9207e74ee38efd","d347ee29ce61455392e994fe8d8db53d","7a1bfe94867a4d97ad06e37eda64d1ee","a06b1ec0a9064b0e9e24bab6457e05c2","1a561be590f4498f8f77d8fbbe400a69","6b371f3e2fa44008b82fa8a084e87a9b","952e2bb1afb645d991acdfad42e1fe1d","f174e3fd04354ed085718febba12b385","85c4b8f301354b8eaeb91015aac4c709","2fa2e2d8b4fd450c8b033f4d75056399","10c71733774e4954a6a4d8109bb7ebdc","5ef9830ab2034226b38e4a9242977533","5a3c365627c0469b90b956fa0ee5f718","9a19988d574045529bffebdca851f13c","4b7fc98869834347a9844b57dcee26b2","80ca5d19a28e4a059bdacdf5261ba4f0","9fe132d9dbb94e5c9a65340a17f8ac4c","541bd0b6c0f74201b3fef130ffcfe642","38c8bc8659a64ddb9df43730a4ae1ffa","d0ff1a0534554aeea9f3b60873c47078","d64abb8ce2674fc39b80e06dd261d4e4","6a35ed4ff7c94a0895143f2ec5646dec"]},"id":"js_QGa1jK9xu","outputId":"3217bdd5-3006-4774-da61-d23a0896ebd2"},"outputs":[{"output_type":"display_data","data":{"text/plain":["Downloading (…)ve/main/spiece.model:   0%|          | 0.00/798k [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"7c743c61c32348508ba8f62d77a5d0b7"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["Downloading (…)lve/main/config.json:   0%|          | 0.00/760 [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"5ed9dea6dac94ce9ba9207e74ee38efd"}},"metadata":{}},{"output_type":"stream","name":"stdout","text":["cpu\n"]},{"output_type":"display_data","data":{"text/plain":["Downloading pytorch_model.bin:   0%|          | 0.00/467M [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"5ef9830ab2034226b38e4a9242977533"}},"metadata":{}},{"output_type":"stream","name":"stderr","text":["Some weights of the model checkpoint at xlnet-base-cased were not used when initializing XLNetModel: ['lm_loss.bias', 'lm_loss.weight']\n","- This IS expected if you are initializing XLNetModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing XLNetModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"]},{"output_type":"stream","name":"stdout","text":["############# Epoch 1: Training Start   #############\n"]}],"source":["MAX_LEN = 256\n","TRAIN_BATCH_SIZE = 32\n","VALID_BATCH_SIZE = 32\n","EPOCHS = 5\n","LEARNING_RATE= 1e-05\n","\n","targets_settings =[\n","   ['Spiritual', 'Physical', 'Intellectual', 'Social', 'Vocational','Emotional'],\n","   ['Physical', 'Intellectual', 'Social', 'Vocational','Spiritual_Emotional'],\n","   [ 'Intellectual', 'Social', 'Vocational','Physical_Spiritual_Emotional'],\n","   [ 'Social', 'Intellectual_Vocational','Physical_Spiritual_Emotional']\n","]\n","classifier_index = 4 #Models\n","target_index = 0 # [0: 6-dim, 1:5-dim, 2:4-dim, 3:3-dim]\n","ran_index = 1 #d[0:200, 1:345, 2:546]\n","\n","Classifiers = [\"nghuyong/ernie-2.0-en\", \"bert-base-uncased\",\"roberta-base\" ,\"emilyalsentzer/Bio_ClinicalBERT\", \"xlnet-base-cased\",'nlptown/bert-base-multilingual-uncased-sentiment', \"mental/mental-bert-base-uncased\"]\n","Classifiers_Abs = [\"ERNIE\", \"BERT\", \"RoBERTa\", \"ClinicalBERT\", \"XLNET\", \"PsychBERT\", \"Mental-BERT\"]\n","TheClassifier = Classifiers[classifier_index]\n","TheClassifier_Abstract = Classifiers_Abs[classifier_index]\n","\n","rand_states = [200, 345, 546]\n","\n","\n","rand_state = rand_states[ran_index]\n","\n","target_List = targets_settings[target_index]\n","dimension = len(target_List)\n","\n","import pandas as pd\n","import numpy as np\n","\n","data=pd.read_csv(\"/content/drive/MyDrive/Wellness_Dataset_Paper/MultiLabel_WD - Sheet1 (1) (1).csv\") # MultiLabel_WD.csv is the first Dataset\n","\n","data=data.astype({'Spiritual':'float', 'Physical':'float', 'Intellectual':'float', 'Social':'float', 'Vocational':'float',\n","       'Emotional':'float'})\n","\n","tokenizer = XLNetTokenizer.from_pretrained(\"xlnet-base-cased\")\n","# print(data)\n","labels_name = data.columns\n","\n","labels_name = labels_name[1:]\n","labels = data[labels_name]\n","\n","counts = np.zeros(dimension)\n","for i in range(len(data)):\n","  for j in range(dimension):\n","    if data.loc[i][labels_name[j]]>0:\n","      counts[j] += 1\n","\n","labels_dic ={labels_name[i]:counts[i] for i in range(dimension)}\n","data_d5 = data.copy(deep=True)\n","data_d4 = data.copy(deep=True)\n","data_d3 = data.copy(deep=True)\n","\n","data_d5['Spiritual_Emotional'] = data_d5[[ 'Spiritual', 'Emotional']].max(axis=1)\n","data_d5 = data_d5.drop(['Spiritual', 'Emotional'], axis=1)\n","\n","data_d4['Physical_Spiritual_Emotional'] = data_d4[['Physical', 'Spiritual', 'Emotional']].max(axis=1)\n","data_d4 = data_d4.drop(['Physical','Spiritual', 'Emotional'], axis=1)\n","\n","data_d3 = data_d4.copy(deep=True)\n","data_d3['Intellectual_Vocational'] = data_d3[['Intellectual', 'Vocational']].max(axis=1)\n","data_d3 = data_d3.drop(['Intellectual', 'Vocational'], axis=1)\n","\n","if dimension==5:\n","   data=data_d5\n","elif dimension==4:\n","   data=data_d4\n","elif dimension==3:\n","   data=data_d3\n","\n","\n","from transformers import AutoTokenizer, AutoModel, XLNetTokenizer,XLNetModel\n","#tokenizer = AutoTokenizer.from_pretrained(TheClassifier)\n","import torch\n","\n","class CustomDataset(torch.utils.data.Dataset):\n","    def __init__(self, df, tokenizer, max_len):\n","        self.tokenizer = tokenizer\n","        self.df = df\n","        self.title = df['text']\n","        self.targets = self.df[target_List].values\n","        self.max_len = max_len\n","\n","    def __len__(self):\n","        return len(self.title)\n","\n","    def __getitem__(self, index):\n","        title = str(self.title[index])\n","        title = \" \".join(title.split())\n","\n","        inputs = self.tokenizer.encode_plus(\n","            title,\n","            None,\n","            add_special_tokens=True,\n","            max_length=self.max_len,\n","            padding='max_length',\n","            return_token_type_ids=True,\n","            truncation=True,\n","            return_attention_mask=True,\n","            return_tensors='pt'\n","        )\n","\n","        return {\n","            'input_ids': inputs['input_ids'].flatten(),\n","            'attention_mask': inputs['attention_mask'].flatten(),\n","            'token_type_ids': inputs[\"token_type_ids\"].flatten(),\n","            'targets': torch.FloatTensor(self.targets[index])\n","        }\n","\n","test_size = 0.2\n","val_df = data.sample(frac=test_size, random_state=rand_state).reset_index (drop=True)\n","train_df = data.drop (val_df.index).reset_index (drop=True)\n","train_dataset=CustomDataset(train_df, tokenizer, MAX_LEN)\n","valid_dataset=CustomDataset(val_df,tokenizer,MAX_LEN)\n","\n","train_data_loader = torch.utils.data.DataLoader (\n","train_dataset,\n","shuffle=True,\n","batch_size=TRAIN_BATCH_SIZE,\n","num_workers=0\n",")\n","val_data_loader = torch.utils.data.DataLoader (\n","valid_dataset,\n","shuffle=False,\n","batch_size=VALID_BATCH_SIZE,\n","num_workers=0\n",")\n","\n","device=torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')\n","print(device)\n","def load_ckp(checkpoint_fpath, model, optimizer):\n","    \"\"\"\n","    checkpoint_path: path to save checkpoint\n","    model: model that we want to load checkpoint parameters into\n","    optimizer: optimizer we defined in previous training\n","    \"\"\"\n","    # load check point\n","    checkpoint = torch.load(checkpoint_fpath)\n","    # initialize state_dict from checkpoint to model\n","    model.load_state_dict(checkpoint['state_dict'])\n","    # initialize optimizer from checkpoint to optimizer\n","    optimizer.load_state_dict(checkpoint['optimizer'])\n","    # initialize valid_loss_min from checkpoint to valid_loss_min\n","    valid_loss_min = checkpoint['valid_loss_min']\n","    # return model, optimizer, epoch value, min validation loss\n","    return model, optimizer, checkpoint['epoch'], valid_loss_min.item()\n","\n","def save_ckp(state, is_best, checkpoint_path, best_model_path):\n","    \"\"\"\n","    state: checkpoint we want to save\n","    is_best: is this the best checkpoint; min validation loss\n","    checkpoint_path: path to save checkpoint\n","    best_model_path: path to save best model\n","    \"\"\"\n","    f_path = checkpoint_path\n","    # save checkpoint data to the path given, checkpoint_path\n","    torch.save(state, f_path)\n","    # if it is a best model, min validation loss\n","    if is_best:\n","        best_fpath = best_model_path\n","        # copy that checkpoint file to best path given, best_model_path\n","        shutil.copyfile(f_path, best_fpath)\n","if classifier_index==4:\n","  class XLNETClass(torch.nn.Module):\n","    def __init__(self):\n","        super(XLNETClass, self).__init__()\n","        self.xlnet_model = XLNetModel.from_pretrained(\"xlnet-base-cased\", output_hidden_states=True, output_attentions=True, return_dict=True)\n","        self.dropout = torch.nn.Dropout(0.3)\n","        self.linear = torch.nn.Linear(768, dimension + 1)\n","\n","    def forward(self, input_ids, attn_mask, token_type_ids):\n","        output_dict = self.xlnet_model(\n","            input_ids=input_ids,\n","            attention_mask=attn_mask,\n","            token_type_ids=token_type_ids,\n","            output_hidden_states=True,\n","            return_dict=True\n","        )\n","        last_hidden_state = output_dict.last_hidden_state\n","        attention_weights = output_dict.attentions\n","        output_dropout = self.dropout(last_hidden_state[:, -1, :])\n","        output = self.linear(output_dropout)\n","        return output, attention_weights[-1]\n","\n","  model = XLNETClass()\n","  model.to(device)\n","\n","def loss_fn(m_outputs, targets):\n","        reward = dimension\n","\n","        tensor_temp = torch.zeros(32,dtype=torch.float)\n","        tensor_temp.to(device)\n","        outputs = torch.nn.functional.softmax(m_outputs, dim=1,dtype=torch.float)\n","\n","        outputs, reservation = outputs[:, :-1], outputs[:, -1]\n","\n","        # gain = torch.gather(outputs, dim=1, index=targets).squeeze()\n","        # print(\"targets:\",targets)\n","        # print(\"outputs:\", outputs)\n","        # raise KeyboardInterrupt\n","        # return targets, outputs\n","        gain = torch.einsum(\"ij, ij -> i\", targets.to(torch.float), outputs)\n","\n","        # doubling_rate = (gain.max() + reservation / reward).log()\n","        doubling_rate = -torch.log(gain + reservation/reward)\n","        return  doubling_rate.mean(), reservation\n","\n","def loss_fn2(outputs, targets):\n","    # return torch.nn.BCEWithLogitsLoss()(outputs[:,:-1], targets)\n","    return torch.nn.CrossEntropyLoss()(outputs[:, :-1], targets)\n","\n","optimizer = torch.optim.Adam(params =  model.parameters(), lr=LEARNING_RATE)\n","val_targets=[]\n","val_outputs=[]\n","\n","\n","def train_model(n_epochs, training_loader, validation_loader, model,\n","                optimizer, checkpoint_path, best_model_path):\n","\n","  # initialize tracker for minimum validation loss\n","  valid_loss_min = np.Inf\n","\n","\n","  for epoch in range(1, n_epochs+1):\n","    train_loss = 0\n","    valid_loss = 0\n","\n","    model.train()\n","    print('############# Epoch {}: Training Start   #############'.format(epoch))\n","    for batch_idx, data in enumerate(training_loader):\n","        #print('yyy epoch', batch_idx)\n","        ids = data['input_ids'].to(device, dtype = torch.long)\n","        mask = data['attention_mask'].to(device, dtype = torch.long)\n","        token_type_ids = data['token_type_ids'].to(device, dtype = torch.long)\n","        targets = data['targets'].to(device, dtype = torch.float)\n","\n","        outputs = model(ids, mask, token_type_ids)\n","\n","        optimizer.zero_grad()\n","        loss, _ = loss_fn(outputs, targets.type(torch.int64))\n","        # tar, outp = loss_fn(outputs, targets.type(torch.int64))\n","        # return tar, outp\n","\n","        # print(len(targets))\n","        loss2 = loss_fn2(outputs, targets)\n","\n","\n","\n","        optimizer.zero_grad()\n","        loss.backward()\n","        optimizer.step()\n","        #print('before loss data in training', loss.item(), train_loss)\n","        train_loss = train_loss + ((1 / (batch_idx + 1)) * (loss.item() - train_loss))\n","        #print('after loss data in training', loss.item(), train_loss)\n","\n","    print('############# Epoch {}: Training End     #############'.format(epoch))\n","\n","    print('############# Epoch {}: Validation Start   #############'.format(epoch))\n","    ######################\n","    # validate the model #\n","    ######################\n","\n","    model.eval()\n","\n","    with torch.no_grad():\n","      for batch_idx, data in enumerate(validation_loader, 0):\n","            ids = data['input_ids'].to(device, dtype = torch.long)\n","            mask = data['attention_mask'].to(device, dtype = torch.long)\n","            token_type_ids = data['token_type_ids'].to(device, dtype = torch.long)\n","            targets = data['targets'].to(device, dtype = torch.float)\n","            outputs = model(ids, mask, token_type_ids)\n","\n","            loss, _ = loss_fn(outputs, targets.type(torch.int64))\n","\n","            valid_loss = valid_loss + ((1 / (batch_idx + 1)) * (loss.item() - valid_loss))\n","            val_targets.extend(targets.cpu().detach().numpy().tolist())\n","            val_outputs.extend(torch.sigmoid(outputs).cpu().detach().numpy().tolist())\n","\n","      print('############# Epoch {}: Validation End     #############'.format(epoch))\n","      # calculate average losses\n","      #print('before cal avg train loss', train_loss)\n","      train_loss = train_loss/len(training_loader)\n","      valid_loss = valid_loss/len(validation_loader)\n","      # print training/validation statistics\n","      print('Epoch: {} \\tAverage Training Loss: {:.6f} \\tAverage Validation Loss: {:.6f}'.format(\n","            epoch,\n","            train_loss,\n","            valid_loss\n","            ))\n","\n","      # create checkpoint variable and add important data\n","      checkpoint = {\n","            'epoch': epoch + 1,\n","            'valid_loss_min': valid_loss,\n","            'state_dict': model.state_dict(),\n","            'optimizer': optimizer.state_dict()\n","      }\n","        # save checkpoint\n","    #   save_ckp(checkpoint, False, checkpoint_path, best_model_path)\n","\n","      ## TODO: save the model if validation loss has decreased\n","      if valid_loss <= valid_loss_min:\n","        print('Validation loss decreased ({:.6f} --> {:.6f}).  Saving model ...'.format(valid_loss_min,valid_loss))\n","        # save checkpoint as best model\n","        # save_ckp(checkpoint, True, checkpoint_path, best_model_path)\n","        valid_loss_min = valid_loss\n","\n","    print('############# Epoch {}  Done   #############\\n'.format(epoch))\n","\n","  return model\n","\n","import shutil, sys\n","\n","model = train_model(EPOCHS, train_data_loader, val_data_loader, model, optimizer, \"/ckpt_path\", \"/best.pt\")\n","\n","def finalLabels2(predicted_list,val_list):\n","\n","  indices=np.array(predicted_list).argsort()[::-1][:int(sum(val_list))]\n","  # argsort()[:-1][:n]\n","  # print(predicted_list,np.array(predicted_list[i]).argsort()[::-1][:int(sum(val_list[i]))])\n","  for j in range(len(predicted_list)):\n","    if j in indices:\n","      predicted_list[j]=1.0\n","    else:\n","      predicted_list[j]=0.0\n","  return predicted_list\n","\n","final_list=[]\n","# for i in val_df['text']:\n","#   example = i\n","for i in range(len(val_df)):\n","  example  = val_df.loc[i]['text']\n","  target  = [val_df.loc[i][j+1] for j in range(dimension)]\n","  encodings = tokenizer.encode_plus(\n","      example,\n","      None,\n","      add_special_tokens=True,\n","      max_length=MAX_LEN,\n","      padding='max_length',\n","      return_token_type_ids=True,\n","      truncation=True,\n","      return_attention_mask=True,\n","      return_tensors='pt'\n","  )\n","  model.eval()\n","  with torch.no_grad():\n","      input_ids = encodings['input_ids'].to(device, dtype=torch.long)\n","      attention_mask = encodings['attention_mask'].to(device, dtype=torch.long)\n","      token_type_ids = encodings['token_type_ids'].to(device, dtype=torch.long)\n","      output = model(input_ids, attention_mask, token_type_ids)\n","      temp = torch.Tensor(target).type(torch.int64).to(device)\n","      loss, reservation = loss_fn(output,temp.reshape([1,dimension]))\n","      final_output = torch.sigmoid(output).cpu().detach().numpy().tolist()\n","      # print(train_df.columns[1:].to_list()[int(np.argmax(final_output, axis=1))])\n","      # final=[0 if i<0.4 else 1 for i in final_output[0]]\n","      # print(\"final\",final)\n","      # print(final_output[0][:-1], target)\n","      temp = finalLabels2(final_output[0][:-1],target)\n","    #   print(temp)\n","    #   print(len(temp))\n","    #   print(target)\n","    #   print(len(target))\n","\n","      final_list.append(temp+target+torch.Tensor.tolist(reservation))\n","\n","from operator import itemgetter\n","sorted_final_list = sorted(final_list, key=itemgetter(2*dimension - 1), reverse = False)\n","\n","from sklearn.metrics import multilabel_confusion_matrix, confusion_matrix\n","\n","def get_accuracies(true_labels, predictions):\n","    #https://scikit-learn.org/stable/modules/generated/sklearn.metrics.multilabel_confusion_matrix.html\n","    cm = multilabel_confusion_matrix(true_labels, predictions)\n","    total_count = np.array(true_labels).shape[0]\n","    accuracies = []\n","    # print(np.array(true_labels).shape[1])\n","    # raise KeyboardInterrupt\n","    for i in range(np.array(true_labels).shape[1]):\n","        true_positive_count = np.sum(cm[i,1,1]).item()\n","        true_negative_count = np.sum(cm[i,0,0]).item()\n","        accuracy = (true_positive_count + true_negative_count) / total_count\n","        accuracies.append(accuracy)\n","    return accuracies\n","\n","\n","from sklearn.metrics import classification_report\n","from sklearn.metrics import classification_report\n","from sklearn.metrics import matthews_corrcoef\n","from sklearn.metrics import accuracy_score\n","label_names = target_List\n","for threshold in [1, .95, 0.9, 0.85, 0.8,.75]:\n","  list_data = sorted_final_list[:round(threshold*len(sorted_final_list)-1)]\n","  val_list = [list_data[i][dimension:2*dimension] for i in range(len(list_data))]\n","  prediction = [list_data[i][0:dimension] for i in range(len(list_data))]\n","  # print(val_list)\n","  # print(prediction)\n","  # print(dimension,len(val_list), len(prediction))\n","  # raise KeyboardInterrupt\n","  print('############# '+TheClassifier_Abstract+'_Dim'+str(dimension)+'_run'+str(rand_state)+'_threshold'+str(threshold)+'   #############')\n","\n","  print(classification_report(val_list, prediction,target_names=label_names))\n","\n","  accuracies = get_accuracies(val_list,prediction)\n","  accuracies = [round(accuracies[i],2) for i in range(dimension)]\n","  print(\"accuracies for each class:\",accuracies)\n","\n","  val = pd.DataFrame(val_list, columns = target_List)\n","  fin = pd.DataFrame(prediction, columns = target_List)\n","\n","  print('MCC:')\n","\n","  for i in range(dimension):\n","     label = target_List[i]\n","     print(label, matthews_corrcoef(val[label],fin[label]))\n","#   print(\"Physical\", matthews_corrcoef(val[\"Physical\"],fin[\"Physical\"]))\n","#   print(\"Spiritual\", matthews_corrcoef(val[\"Spiritual\"],fin[\"Spiritual\"]))\n","#   print(\"Intellectual\", matthews_corrcoef(val[\"Intellectual\"],fin[\"Intellectual\"]))\n","#   print(\"Social\", matthews_corrcoef(val[\"Social\"],fin[\"Social\"]))\n","#   print(\"Vocational\", matthews_corrcoef(val[\"Vocational\"],fin[\"Vocational\"]))\n","#   print(\"Emotional\", matthews_corrcoef(val[\"Emotional\"],fin[\"Emotional\"]))\n","\n","print('Done!!!!!!!!!!!!')"]}]}