{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[{"file_id":"1Pyu70NsBE7ikh0UnVwpO-7TwFErveW-z","timestamp":1690258027891}],"gpuType":"T4","collapsed_sections":["IzxARdRKPVY_","Wf28VvAsRkaF","0CYNNM4XSmHP"]},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU","widgets":{"application/vnd.jupyter.widget-state+json":{"3839d3805fbf42ad8f6eb808d367c538":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_ad5c31cc114f4254bb10a1569fb7c3ee","IPY_MODEL_2097d1aa5a994c4b8e2a8553fd4e3ba4","IPY_MODEL_e0104b70474942769bd30a7fdb7aad48"],"layout":"IPY_MODEL_2feb231f30194d1885b52f249e81b039"}},"ad5c31cc114f4254bb10a1569fb7c3ee":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_7e5c3139c90c4ef0b7e134e0e97027e0","placeholder":"​","style":"IPY_MODEL_cf90b25c0203487c9bfdf1c447aa9d86","value":"Downloading (…)okenizer_config.json: 100%"}},"2097d1aa5a994c4b8e2a8553fd4e3ba4":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_b7b1e8c6df924edea0803473b41c62b7","max":321,"min":0,"orientation":"horizontal","style":"IPY_MODEL_0fedd6b7f6bf4052932a1ecfce9d206d","value":321}},"e0104b70474942769bd30a7fdb7aad48":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_6621f1f6c63746f9b5a9ab383d72b0ca","placeholder":"​","style":"IPY_MODEL_8932cf647a954834a67faca684ddab83","value":" 321/321 [00:00&lt;00:00, 25.1kB/s]"}},"2feb231f30194d1885b52f249e81b039":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"7e5c3139c90c4ef0b7e134e0e97027e0":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"cf90b25c0203487c9bfdf1c447aa9d86":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"b7b1e8c6df924edea0803473b41c62b7":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"0fedd6b7f6bf4052932a1ecfce9d206d":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"6621f1f6c63746f9b5a9ab383d72b0ca":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"8932cf647a954834a67faca684ddab83":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"f9af4bb9ea0045018d2a48eb157db8a9":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_a4a5a894d0014b3abadcb4de6e1baf64","IPY_MODEL_4fd903ef05364c00b7d10f12a11255c2","IPY_MODEL_0636287bae7b4e5fa3bbda1c58247add"],"layout":"IPY_MODEL_9b3bcf2ed85c4131be0a6c207562f3cf"}},"a4a5a894d0014b3abadcb4de6e1baf64":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_8783933ae5c64c779d223e3571c1df2f","placeholder":"​","style":"IPY_MODEL_c1b4319da9e3479297c7f7f6cdef2843","value":"Downloading (…)solve/main/vocab.txt: 100%"}},"4fd903ef05364c00b7d10f12a11255c2":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_73d5b6d0a5bf488992f390e1fcfed747","max":231508,"min":0,"orientation":"horizontal","style":"IPY_MODEL_864053b8bad248118d8bcbc12cc027f3","value":231508}},"0636287bae7b4e5fa3bbda1c58247add":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_4e6d1ec263124b28ab2d82287ab0fe5a","placeholder":"​","style":"IPY_MODEL_c93cca109fc74727bcfc7bbca3335696","value":" 232k/232k [00:00&lt;00:00, 4.11MB/s]"}},"9b3bcf2ed85c4131be0a6c207562f3cf":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"8783933ae5c64c779d223e3571c1df2f":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"c1b4319da9e3479297c7f7f6cdef2843":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"73d5b6d0a5bf488992f390e1fcfed747":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"864053b8bad248118d8bcbc12cc027f3":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"4e6d1ec263124b28ab2d82287ab0fe5a":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"c93cca109fc74727bcfc7bbca3335696":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"2d8c6eb4dbf74e67b86789ef2ed2c6be":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_ae4542f3078a4d0bb31e1603a58d307a","IPY_MODEL_28b432109f734894b8b30c299c9ca9f8","IPY_MODEL_91a0d29435e84ddc816d56b7cbef07e4"],"layout":"IPY_MODEL_937a4b1b6a184deab513b20859776a53"}},"ae4542f3078a4d0bb31e1603a58d307a":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_7820bc8b666d4d179b5f6721bfc8c468","placeholder":"​","style":"IPY_MODEL_aea7e6943188484b89220fd881fd9be4","value":"Downloading (…)/main/tokenizer.json: 100%"}},"28b432109f734894b8b30c299c9ca9f8":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_cc6cf0af294a409d86fdaa746c768986","max":466081,"min":0,"orientation":"horizontal","style":"IPY_MODEL_26f44c136fbc47c08d3a3d00e2d7f72a","value":466081}},"91a0d29435e84ddc816d56b7cbef07e4":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_c214879d085a41c8aec5e863625261ad","placeholder":"​","style":"IPY_MODEL_ad0e31b3f5a7466e82c6070de664fedb","value":" 466k/466k [00:00&lt;00:00, 26.3MB/s]"}},"937a4b1b6a184deab513b20859776a53":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"7820bc8b666d4d179b5f6721bfc8c468":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"aea7e6943188484b89220fd881fd9be4":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"cc6cf0af294a409d86fdaa746c768986":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"26f44c136fbc47c08d3a3d00e2d7f72a":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"c214879d085a41c8aec5e863625261ad":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"ad0e31b3f5a7466e82c6070de664fedb":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"4036595cbf2045b4894b442b05d05ee1":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_12e7c52b76f34a4a928ba777c712731e","IPY_MODEL_ec651431687e40c580f7e1a210b89343","IPY_MODEL_9bd57d13e9da4fc68b23225acd5a2cfc"],"layout":"IPY_MODEL_303a00dd2ae9417b9a34798b9fdc05f7"}},"12e7c52b76f34a4a928ba777c712731e":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_7716ab9b2e3746b488758d02b179a4c7","placeholder":"​","style":"IPY_MODEL_fc1cbbb589cc4279bfda8aed7ef39976","value":"Downloading (…)cial_tokens_map.json: 100%"}},"ec651431687e40c580f7e1a210b89343":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_1fee1dbaa1bb4e7e9afd40df0432d37e","max":112,"min":0,"orientation":"horizontal","style":"IPY_MODEL_9434a8a87fa4425c9e0f310a92a90b84","value":112}},"9bd57d13e9da4fc68b23225acd5a2cfc":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_05b6ff8f69c0490ca9a3b55407d81f11","placeholder":"​","style":"IPY_MODEL_9ffb263376644821b1776dd7c27a47c7","value":" 112/112 [00:00&lt;00:00, 5.88kB/s]"}},"303a00dd2ae9417b9a34798b9fdc05f7":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"7716ab9b2e3746b488758d02b179a4c7":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"fc1cbbb589cc4279bfda8aed7ef39976":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"1fee1dbaa1bb4e7e9afd40df0432d37e":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"9434a8a87fa4425c9e0f310a92a90b84":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"05b6ff8f69c0490ca9a3b55407d81f11":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"9ffb263376644821b1776dd7c27a47c7":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"3e6e0ce2024c4381b7e0a893b99f02a6":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_3ef8159fa4064f8ebf74b3946bf0dbca","IPY_MODEL_2e8418b943a74bf482c7631fe8ae3cfd","IPY_MODEL_73bdec30561b4646bca818238466acad"],"layout":"IPY_MODEL_7b1f3c8a60304e7ea709f42115c7114a"}},"3ef8159fa4064f8ebf74b3946bf0dbca":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_eabba3e35f9c42fc9198fdd276f8d009","placeholder":"​","style":"IPY_MODEL_892dab9a0df04e119a36a457f7787014","value":"Downloading (…)lve/main/config.json: 100%"}},"2e8418b943a74bf482c7631fe8ae3cfd":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_c4021d56fe0748bdbedaf4af98f627a9","max":639,"min":0,"orientation":"horizontal","style":"IPY_MODEL_da9e7cb55a5d422382793cb45c0f14e3","value":639}},"73bdec30561b4646bca818238466acad":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_4a94da7780f742708711d0c55b69e943","placeholder":"​","style":"IPY_MODEL_9292b1af56704fa18cfdef8d6bad5e30","value":" 639/639 [00:00&lt;00:00, 36.8kB/s]"}},"7b1f3c8a60304e7ea709f42115c7114a":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"eabba3e35f9c42fc9198fdd276f8d009":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"892dab9a0df04e119a36a457f7787014":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"c4021d56fe0748bdbedaf4af98f627a9":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"da9e7cb55a5d422382793cb45c0f14e3":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"4a94da7780f742708711d0c55b69e943":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"9292b1af56704fa18cfdef8d6bad5e30":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"88a1de725b8b49158cf6a865f4f0805a":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_e22ec6f0ecfa4185af88f519c8da9f04","IPY_MODEL_bb1ba08bab8242fb8a188202b1fd704c","IPY_MODEL_90df8d261f404309bb1cb6241fa25019"],"layout":"IPY_MODEL_8fea760274a245dc8a9cb6b25881dc2a"}},"e22ec6f0ecfa4185af88f519c8da9f04":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_9b8dd0c7d36d43deaaa2111e42e97c36","placeholder":"​","style":"IPY_MODEL_71810558b55c4b38b0e6c0ca884862f2","value":"Downloading pytorch_model.bin: 100%"}},"bb1ba08bab8242fb8a188202b1fd704c":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_dc1bd44d2e0d47b0a023c9d58cdcb2db","max":438147282,"min":0,"orientation":"horizontal","style":"IPY_MODEL_b92d6325bf0b40178dee23088d3965d3","value":438147282}},"90df8d261f404309bb1cb6241fa25019":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_9b47a22f8e6a4a549d1195465283d267","placeholder":"​","style":"IPY_MODEL_2dc50033d01d4338ae6db70a48698e48","value":" 438M/438M [00:05&lt;00:00, 127MB/s]"}},"8fea760274a245dc8a9cb6b25881dc2a":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"9b8dd0c7d36d43deaaa2111e42e97c36":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"71810558b55c4b38b0e6c0ca884862f2":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"dc1bd44d2e0d47b0a023c9d58cdcb2db":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"b92d6325bf0b40178dee23088d3965d3":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"9b47a22f8e6a4a549d1195465283d267":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"2dc50033d01d4338ae6db70a48698e48":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}}}}},"cells":[{"cell_type":"code","source":["!pip install sentencepiece\n","!pip install transformers\n","!pip install tensorflow_addons"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Fjncg9GrtQE2","executionInfo":{"status":"ok","timestamp":1690348591680,"user_tz":-330,"elapsed":24262,"user":{"displayName":"Vedant Palit","userId":"05232341091904350034"}},"outputId":"5b61c1ba-f8fa-4c89-fe49-7c0f2aecaf3e"},"execution_count":1,"outputs":[{"output_type":"stream","name":"stdout","text":["Collecting sentencepiece\n","  Downloading sentencepiece-0.1.99-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.3 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m16.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hInstalling collected packages: sentencepiece\n","Successfully installed sentencepiece-0.1.99\n","Collecting transformers\n","  Downloading transformers-4.31.0-py3-none-any.whl (7.4 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.4/7.4 MB\u001b[0m \u001b[31m20.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers) (3.12.2)\n","Collecting huggingface-hub<1.0,>=0.14.1 (from transformers)\n","  Downloading huggingface_hub-0.16.4-py3-none-any.whl (268 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m268.8/268.8 kB\u001b[0m \u001b[31m31.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (1.22.4)\n","Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers) (23.1)\n","Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (6.0.1)\n","Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (2022.10.31)\n","Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers) (2.27.1)\n","Collecting tokenizers!=0.11.3,<0.14,>=0.11.1 (from transformers)\n","  Downloading tokenizers-0.13.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (7.8 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.8/7.8 MB\u001b[0m \u001b[31m42.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting safetensors>=0.3.1 (from transformers)\n","  Downloading safetensors-0.3.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.3 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m47.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from transformers) (4.65.0)\n","Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.14.1->transformers) (2023.6.0)\n","Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.14.1->transformers) (4.7.1)\n","Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (1.26.16)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2023.5.7)\n","Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2.0.12)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.4)\n","Installing collected packages: tokenizers, safetensors, huggingface-hub, transformers\n","Successfully installed huggingface-hub-0.16.4 safetensors-0.3.1 tokenizers-0.13.3 transformers-4.31.0\n","Collecting tensorflow_addons\n","  Downloading tensorflow_addons-0.21.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (612 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m612.1/612.1 kB\u001b[0m \u001b[31m7.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from tensorflow_addons) (23.1)\n","Collecting typeguard<3.0.0,>=2.7 (from tensorflow_addons)\n","  Downloading typeguard-2.13.3-py3-none-any.whl (17 kB)\n","Installing collected packages: typeguard, tensorflow_addons\n","Successfully installed tensorflow_addons-0.21.0 typeguard-2.13.3\n"]}]},{"cell_type":"code","source":["from google.colab import drive\n","drive.mount('/content/drive')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"pMobvUxduUL0","executionInfo":{"status":"ok","timestamp":1690348614602,"user_tz":-330,"elapsed":22926,"user":{"displayName":"Vedant Palit","userId":"05232341091904350034"}},"outputId":"3fcd6752-dd81-48ab-ed40-b23ad2fb6f24"},"execution_count":2,"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}]},{"cell_type":"code","source":["from transformers import AutoModel, AutoTokenizer\n","from transformers import XLNetModel, XLNetTokenizer\n","import torch"],"metadata":{"id":"FTJKH48utvSW","executionInfo":{"status":"ok","timestamp":1690348620864,"user_tz":-330,"elapsed":6265,"user":{"displayName":"Vedant Palit","userId":"05232341091904350034"}}},"execution_count":3,"outputs":[]},{"cell_type":"code","source":["import pandas as pd\n","import numpy as np\n","data=pd.read_csv('/content/drive/MyDrive/Wellness_Dataset_Paper/MultiLabel_WD - Sheet1 (1) (1).csv')\n"],"metadata":{"id":"FVSDIkDbYmlV","executionInfo":{"status":"ok","timestamp":1690349381139,"user_tz":-330,"elapsed":592,"user":{"displayName":"Vedant Palit","userId":"05232341091904350034"}}},"execution_count":31,"outputs":[]},{"cell_type":"markdown","source":["#6 Dimensions"],"metadata":{"id":"IzxARdRKPVY_"}},{"cell_type":"code","execution_count":32,"metadata":{"id":"EGVrP2EOBpCC","executionInfo":{"status":"ok","timestamp":1690349381778,"user_tz":-330,"elapsed":1,"user":{"displayName":"Vedant Palit","userId":"05232341091904350034"}}},"outputs":[],"source":["data=data.astype({'Spiritual':'float', 'Physical':'float', 'Intellectual':'float', 'Social':'float', 'Vocational':'float',\n","       'Emotional':'float'})"]},{"cell_type":"code","execution_count":33,"metadata":{"id":"LV3_VLoTBqon","executionInfo":{"status":"ok","timestamp":1690349382482,"user_tz":-330,"elapsed":2,"user":{"displayName":"Vedant Palit","userId":"05232341091904350034"}}},"outputs":[],"source":["dimensions_list = ['Spiritual', 'Physical', 'Intellectual', 'Social', 'Vocational','Emotional']\n","dimension=6"]},{"cell_type":"markdown","source":["#5 Dimensions"],"metadata":{"id":"Wf28VvAsRkaF"}},{"cell_type":"code","execution_count":34,"metadata":{"id":"BS4S2KGLCysI","executionInfo":{"status":"ok","timestamp":1690349384193,"user_tz":-330,"elapsed":2,"user":{"displayName":"Vedant Palit","userId":"05232341091904350034"}}},"outputs":[],"source":["data=data.astype({'Spiritual':'int32', 'Physical':'int32', 'Intellectual':'int32', 'Social':'int32', 'Vocational':'int32',\n","       'Emotional':'int32'})"]},{"cell_type":"code","execution_count":35,"metadata":{"id":"CQwX98YPC0pq","executionInfo":{"status":"ok","timestamp":1690349384746,"user_tz":-330,"elapsed":2,"user":{"displayName":"Vedant Palit","userId":"05232341091904350034"}}},"outputs":[],"source":["data ['Spiritual or Emotional'] = data.Spiritual | data.Emotional"]},{"cell_type":"code","execution_count":36,"metadata":{"id":"_vXb_oGNC2Ww","executionInfo":{"status":"ok","timestamp":1690349385187,"user_tz":-330,"elapsed":2,"user":{"displayName":"Vedant Palit","userId":"05232341091904350034"}}},"outputs":[],"source":["data = data.drop(['Spiritual', 'Emotional'], axis=1)"]},{"cell_type":"code","execution_count":37,"metadata":{"id":"o7bkXLqBC4PV","executionInfo":{"status":"ok","timestamp":1690349386678,"user_tz":-330,"elapsed":1,"user":{"displayName":"Vedant Palit","userId":"05232341091904350034"}}},"outputs":[],"source":["data=data.astype({ 'Physical':'float', 'Intellectual':'float', 'Social':'float', 'Vocational':'float',\n","       'Spiritual or Emotional':'float'})"]},{"cell_type":"code","execution_count":38,"metadata":{"id":"MdDESklpC7AJ","executionInfo":{"status":"ok","timestamp":1690349387049,"user_tz":-330,"elapsed":1,"user":{"displayName":"Vedant Palit","userId":"05232341091904350034"}}},"outputs":[],"source":["dimensions_list = ['Physical', 'Intellectual', 'Social', 'Vocational','Spiritual or Emotional']\n","dimension=5"]},{"cell_type":"markdown","source":["#4 Dimensions"],"metadata":{"id":"0CYNNM4XSmHP"}},{"cell_type":"code","execution_count":39,"metadata":{"id":"qdOOfZNaDXVb","executionInfo":{"status":"ok","timestamp":1690349388145,"user_tz":-330,"elapsed":1,"user":{"displayName":"Vedant Palit","userId":"05232341091904350034"}}},"outputs":[],"source":["data=data.astype({ 'Physical':'float', 'Intellectual':'float', 'Social':'float', 'Vocational':'float',\n","       'Spiritual or Emotional':'float'})"]},{"cell_type":"code","execution_count":40,"metadata":{"id":"82j193L-Dd3J","executionInfo":{"status":"ok","timestamp":1690349388735,"user_tz":-330,"elapsed":1,"user":{"displayName":"Vedant Palit","userId":"05232341091904350034"}}},"outputs":[],"source":["data=data.astype({'Spiritual or Emotional':'int32', 'Physical':'int32', 'Intellectual':'int32', 'Social':'int32', 'Vocational':'int32',\n","       })"]},{"cell_type":"code","execution_count":41,"metadata":{"id":"4jRhTaH8DfT2","executionInfo":{"status":"ok","timestamp":1690349390526,"user_tz":-330,"elapsed":1,"user":{"displayName":"Vedant Palit","userId":"05232341091904350034"}}},"outputs":[],"source":["data ['Spiritual or Emotional or Physical'] = data ['Spiritual or Emotional'] | data['Physical']"]},{"cell_type":"code","execution_count":42,"metadata":{"id":"2WHbBtl2Dg6c","executionInfo":{"status":"ok","timestamp":1690349391186,"user_tz":-330,"elapsed":6,"user":{"displayName":"Vedant Palit","userId":"05232341091904350034"}}},"outputs":[],"source":["data = data.drop(['Physical'], axis=1)"]},{"cell_type":"code","execution_count":43,"metadata":{"id":"UFxebINXDiLu","executionInfo":{"status":"ok","timestamp":1690349391868,"user_tz":-330,"elapsed":1,"user":{"displayName":"Vedant Palit","userId":"05232341091904350034"}}},"outputs":[],"source":["data=data.drop(['Spiritual or Emotional'], axis=1)"]},{"cell_type":"code","execution_count":44,"metadata":{"id":"Tl52AAkIDjm1","executionInfo":{"status":"ok","timestamp":1690349391868,"user_tz":-330,"elapsed":1,"user":{"displayName":"Vedant Palit","userId":"05232341091904350034"}}},"outputs":[],"source":["data=data.astype({  'Intellectual':'float', 'Social':'float', 'Vocational':'float',\n","       'Spiritual or Emotional or Physical':'float'})"]},{"cell_type":"code","execution_count":45,"metadata":{"id":"WM9bv7lcDlYp","executionInfo":{"status":"ok","timestamp":1690349393099,"user_tz":-330,"elapsed":2,"user":{"displayName":"Vedant Palit","userId":"05232341091904350034"}}},"outputs":[],"source":["dimensions_list = ['Intellectual', 'Social', 'Vocational','Spiritual or Emotional or Physical']\n","dimension=4"]},{"cell_type":"markdown","source":["#Main"],"metadata":{"id":"wUbRZ0_aVZSW"}},{"cell_type":"code","source":["MAX_LEN = 64\n","TRAIN_BATCH_SIZE = 2\n","VALID_BATCH_SIZE = 2\n","EPOCHS = 5\n","LEARNING_RATE= 1e-05\n","\n","#dimension = 6\n","#dimensions_list = ['Spiritual', 'Physical', 'Intellectual', 'Social', 'Vocational','Emotional']\n","# threshold = 1 #\n","Classifiers = [\"nghuyong/ernie-2.0-en\", \"bert-base-uncased\",\"roberta-base\" ,\"emilyalsentzer/Bio_ClinicalBERT\", \"xlnet-base-cased\",'nlptown/bert-base-multilingual-uncased-sentiment', \"mental/mental-bert-base-uncased\"]\n","Classifiers_Abs = [\"ERNIE\", \"BERT\", \"RoBERTa\", \"ClinicalBERT\", \"XLNET\", \"PsychBERT\", \"Mental-BERT\"]\n","classifier_index = 6#set as needed\n","TheClassifier = Classifiers[classifier_index]\n","TheClassifier_Abstract = Classifiers_Abs[classifier_index]\n","\n","rand_states = [345, 546,200]\n","ran_index = 0\n","rand_state = rand_states[ran_index]\n","\n","target_List = dimensions_list"],"metadata":{"id":"berITLWfZIK-","executionInfo":{"status":"ok","timestamp":1690349400584,"user_tz":-330,"elapsed":389,"user":{"displayName":"Vedant Palit","userId":"05232341091904350034"}}},"execution_count":46,"outputs":[]},{"cell_type":"code","source":["import torch\n","device=torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')\n","class CustomDataset(torch.utils.data.Dataset):\n","  def __init__(self, df, tokenizer, max_len):\n","        self.tokenizer = tokenizer\n","        self.df = df\n","        self.title = df['text']\n","        self.targets = self.df[target_List].values\n","        self.max_len = max_len\n","\n","  def __len__(self):\n","        return len(self.title)\n","\n","  def __getitem__(self, index):\n","        # print(index,\":\",self.title[index])\n","        # print(self.title[index])\n","        title = self.title[index]\n","        title = \" \".join(title.split())\n","        inputs = self.tokenizer.encode_plus(\n","            title,\n","            None,\n","            add_special_tokens=True,\n","            max_length=self.max_len,\n","            padding='max_length',\n","            return_token_type_ids=True,\n","            truncation=True,\n","            return_attention_mask=True,\n","            return_tensors='pt'\n","        )\n","        return {\n","            'input_ids': inputs['input_ids'].flatten(),\n","            'attention_mask': inputs['attention_mask'].flatten(),\n","            'token_type_ids': inputs[\"token_type_ids\"].flatten(),\n","            'targets': torch.FloatTensor(self.targets[index])\n","        }"],"metadata":{"id":"nLdQ3zL0Zv7v","executionInfo":{"status":"ok","timestamp":1690349403371,"user_tz":-330,"elapsed":513,"user":{"displayName":"Vedant Palit","userId":"05232341091904350034"}}},"execution_count":47,"outputs":[]},{"cell_type":"code","source":["if classifier_index==0:\n","  tokenizer = AutoTokenizer.from_pretrained('nghuyong/ernie-2.0-en')\n","  class ERNIEClass(torch.nn.Module):\n","    def __init__(self):\n","        super(ERNIEClass, self).__init__()\n","        self.tokenizer = AutoTokenizer.from_pretrained('nghuyong/ernie-2.0-en')\n","        self.ernie_model = AutoModel.from_pretrained('nghuyong/ernie-2.0-en', output_attentions=True, return_dict=True)\n","        self.dropout = torch.nn.Dropout(0.3)\n","        self.linear = torch.nn.Linear(768, dimension)\n","\n","    def forward(self, input_ids, attn_mask, token_type_ids):\n","        output_dict = self.ernie_model(\n","            input_ids=input_ids,\n","            attention_mask=attn_mask,\n","            token_type_ids=token_type_ids,\n","            output_hidden_states=True,\n","            return_dict=True\n","        )\n","        last_hidden_state = output_dict.last_hidden_state\n","        attention_weights = output_dict.attentions\n","        output_dropout = self.dropout(last_hidden_state[:, -1, :])\n","        output = self.linear(output_dropout)\n","        return output, attention_weights[-1]\n","\n","  model = ERNIEClass()\n","  model.to(device)\n","\n","if classifier_index==1:\n","  tokenizer=AutoTokenizer.from_pretrained('bert-base-uncased')\n","  class BERTClass(torch.nn.Module):\n","    def __init__(self):\n","        super(BERTClass, self).__init__()\n","        self.tokenizer = AutoTokenizer.from_pretrained('bert-base-uncased')\n","        self.model = AutoModel.from_pretrained('bert-base-uncased',output_hidden_states=True, output_attentions=True, return_dict=True)\n","        self.dropout = torch.nn.Dropout(0.3)\n","        self.linear = torch.nn.Linear(768, dimension)\n","\n","    def forward(self, input_ids, attn_mask, seg_ids):\n","        output = self.model(\n","            input_ids=input_ids,\n","            attention_mask=attn_mask,\n","            token_type_ids=seg_ids\n","        )\n","        output_with_attention = output\n","        output_dropout = self.dropout(output.last_hidden_state[:, 0])\n","        output = self.linear(output_dropout)\n","        return output, output_with_attention\n","\n","\n","\n","  model = BERTClass()\n","  model.to(device)\n","\n","if classifier_index==2:\n","  tokenizer=AutoTokenizer.from_pretrained(\"roberta-base\")\n","  class roBERTaClass(torch.nn.Module):\n","    def __init__(self):\n","        super(roBERTaClass, self).__init__()\n","        self.tokenizer = AutoTokenizer.from_pretrained(\"roberta-base\")\n","        self.model = AutoModel.from_pretrained('roberta-base',output_hidden_states=True, output_attentions=True, return_dict=True)\n","        self.dropout = torch.nn.Dropout(0.3)\n","        self.linear = torch.nn.Linear(768, dimension)\n","\n","    def forward(self, input_ids, attn_mask, seg_ids):\n","        output = self.model(\n","            input_ids=input_ids,\n","            attention_mask=attn_mask,\n","            token_type_ids=seg_ids\n","        )\n","        output_with_attention = output\n","        output_dropout = self.dropout(output.last_hidden_state[:, 0])\n","        output = self.linear(output_dropout)\n","        return output, output_with_attention\n","\n","\n","\n","\n","\n","  model = roBERTaClass()\n","  model.to(device)\n","\n","if classifier_index==3:\n","  tokenizer=AutoTokenizer.from_pretrained('emilyalsentzer/Bio_ClinicalBERT')\n","  class ClinicalBIGBERTClass(torch.nn.Module):\n","    def __init__(self):\n","        super(ClinicalBIGBERTClass, self).__init__()\n","        self.tokenizer = AutoTokenizer.from_pretrained('emilyalsentzer/Bio_ClinicalBERT')\n","        self.model = AutoModel.from_pretrained('emilyalsentzer/Bio_ClinicalBERT',output_hidden_states=True, output_attentions=True, return_dict=True)\n","        self.dropout = torch.nn.Dropout(0.3)\n","        self.linear = torch.nn.Linear(768, dimension)\n","\n","    def forward(self, input_ids, attn_mask, seg_ids):\n","        output = self.model(\n","            input_ids=input_ids,\n","            attention_mask=attn_mask,\n","            token_type_ids=seg_ids\n","        )\n","        output_with_attention = output\n","        output_dropout = self.dropout(output.last_hidden_state[:, 0])\n","        output = self.linear(output_dropout)\n","        return output, output_with_attention\n","  model = ClinicalBIGBERTClass()\n","  model.to(device)"],"metadata":{"id":"P-fW-PUnPtFS","executionInfo":{"status":"ok","timestamp":1690349405873,"user_tz":-330,"elapsed":1,"user":{"displayName":"Vedant Palit","userId":"05232341091904350034"}}},"execution_count":48,"outputs":[]},{"cell_type":"code","source":["if classifier_index==4:\n","  tokenizer = XLNetTokenizer.from_pretrained(\"xlnet-base-cased\")\n","  class XLNETClass(torch.nn.Module):\n","    def __init__(self):\n","        super(XLNETClass, self).__init__()\n","        self.xlnet_model = XLNetModel.from_pretrained(\"xlnet-base-cased\", output_hidden_states=True, output_attentions=True, return_dict=True)\n","        self.dropout = torch.nn.Dropout(0.3)\n","        self.linear = torch.nn.Linear(768, dimension)\n","\n","    def forward(self, input_ids, attn_mask, token_type_ids):\n","        output_dict = self.xlnet_model(\n","            input_ids=input_ids,\n","            attention_mask=attn_mask,\n","            token_type_ids=token_type_ids,\n","            output_hidden_states=True,\n","            return_dict=True\n","        )\n","        last_hidden_state = output_dict.last_hidden_state\n","        attention_weights = output_dict.attentions\n","        output_dropout = self.dropout(last_hidden_state[:, -1, :])\n","        output = self.linear(output_dropout)\n","        return output, attention_weights[-1]\n","\n","  model = XLNETClass()\n","  model.to(device)\n","elif classifier_index==5:\n","  tokenizer=AutoTokenizer.from_pretrained('nlptown/bert-base-multilingual-uncased-sentiment')\n","  class PsychBERTClass(torch.nn.Module):\n","    def __init__(self):\n","        super(PsychBERTClass, self).__init__()\n","        self.tokenizer = AutoTokenizer.from_pretrained('nlptown/bert-base-multilingual-uncased-sentiment')\n","        self.model = AutoModel.from_pretrained('nlptown/bert-base-multilingual-uncased-sentiment',output_hidden_states=True, output_attentions=True, return_dict=True)\n","        self.dropout = torch.nn.Dropout(0.3)\n","        self.linear = torch.nn.Linear(768,dimension)\n","\n","    def forward(self, input_ids, attn_mask, seg_ids):\n","        output = self.model(\n","            input_ids=input_ids,\n","            attention_mask=attn_mask,\n","            token_type_ids=seg_ids\n","        )\n","        output_with_attention = output\n","        output_dropout = self.dropout(output.pooler_output)\n","        output = self.linear(output_dropout)\n","        return output, output_with_attention\n","\n","  model = PsychBERTClass()\n","  model.to(device)\n","\n","elif classifier_index==6:\n","  !huggingface-cli login\n","  tokenizer=AutoTokenizer.from_pretrained('mental/mental-bert-base-uncased',use_auth_token=True)\n","  class MentalBERTClass(torch.nn.Module):\n","    def __init__(self):\n","        super(MentalBERTClass, self).__init__()\n","        self.tokenizer = AutoTokenizer.from_pretrained('mental/mental-bert-base-uncased')\n","        self.model = AutoModel.from_pretrained('mental/mental-bert-base-uncased',output_hidden_states=True, output_attentions=True, return_dict=True)\n","        self.dropout = torch.nn.Dropout(0.3)\n","        self.linear = torch.nn.Linear(768, dimension)\n","\n","    def forward(self, input_ids, attn_mask, seg_ids):\n","        output = self.model(\n","            input_ids=input_ids,\n","            attention_mask=attn_mask,\n","            token_type_ids=seg_ids\n","        )\n","        output_with_attention = output\n","        output_dropout = self.dropout(output.last_hidden_state[:, 0])\n","        output = self.linear(output_dropout)\n","        return output, output_with_attention\n","\n","  model = MentalBERTClass()\n","  model.to(device)"],"metadata":{"id":"MYKdDh35Zy-j","executionInfo":{"status":"ok","timestamp":1690349434008,"user_tz":-330,"elapsed":23989,"user":{"displayName":"Vedant Palit","userId":"05232341091904350034"}},"colab":{"base_uri":"https://localhost:8080/","height":524,"referenced_widgets":["3839d3805fbf42ad8f6eb808d367c538","ad5c31cc114f4254bb10a1569fb7c3ee","2097d1aa5a994c4b8e2a8553fd4e3ba4","e0104b70474942769bd30a7fdb7aad48","2feb231f30194d1885b52f249e81b039","7e5c3139c90c4ef0b7e134e0e97027e0","cf90b25c0203487c9bfdf1c447aa9d86","b7b1e8c6df924edea0803473b41c62b7","0fedd6b7f6bf4052932a1ecfce9d206d","6621f1f6c63746f9b5a9ab383d72b0ca","8932cf647a954834a67faca684ddab83","f9af4bb9ea0045018d2a48eb157db8a9","a4a5a894d0014b3abadcb4de6e1baf64","4fd903ef05364c00b7d10f12a11255c2","0636287bae7b4e5fa3bbda1c58247add","9b3bcf2ed85c4131be0a6c207562f3cf","8783933ae5c64c779d223e3571c1df2f","c1b4319da9e3479297c7f7f6cdef2843","73d5b6d0a5bf488992f390e1fcfed747","864053b8bad248118d8bcbc12cc027f3","4e6d1ec263124b28ab2d82287ab0fe5a","c93cca109fc74727bcfc7bbca3335696","2d8c6eb4dbf74e67b86789ef2ed2c6be","ae4542f3078a4d0bb31e1603a58d307a","28b432109f734894b8b30c299c9ca9f8","91a0d29435e84ddc816d56b7cbef07e4","937a4b1b6a184deab513b20859776a53","7820bc8b666d4d179b5f6721bfc8c468","aea7e6943188484b89220fd881fd9be4","cc6cf0af294a409d86fdaa746c768986","26f44c136fbc47c08d3a3d00e2d7f72a","c214879d085a41c8aec5e863625261ad","ad0e31b3f5a7466e82c6070de664fedb","4036595cbf2045b4894b442b05d05ee1","12e7c52b76f34a4a928ba777c712731e","ec651431687e40c580f7e1a210b89343","9bd57d13e9da4fc68b23225acd5a2cfc","303a00dd2ae9417b9a34798b9fdc05f7","7716ab9b2e3746b488758d02b179a4c7","fc1cbbb589cc4279bfda8aed7ef39976","1fee1dbaa1bb4e7e9afd40df0432d37e","9434a8a87fa4425c9e0f310a92a90b84","05b6ff8f69c0490ca9a3b55407d81f11","9ffb263376644821b1776dd7c27a47c7","3e6e0ce2024c4381b7e0a893b99f02a6","3ef8159fa4064f8ebf74b3946bf0dbca","2e8418b943a74bf482c7631fe8ae3cfd","73bdec30561b4646bca818238466acad","7b1f3c8a60304e7ea709f42115c7114a","eabba3e35f9c42fc9198fdd276f8d009","892dab9a0df04e119a36a457f7787014","c4021d56fe0748bdbedaf4af98f627a9","da9e7cb55a5d422382793cb45c0f14e3","4a94da7780f742708711d0c55b69e943","9292b1af56704fa18cfdef8d6bad5e30","88a1de725b8b49158cf6a865f4f0805a","e22ec6f0ecfa4185af88f519c8da9f04","bb1ba08bab8242fb8a188202b1fd704c","90df8d261f404309bb1cb6241fa25019","8fea760274a245dc8a9cb6b25881dc2a","9b8dd0c7d36d43deaaa2111e42e97c36","71810558b55c4b38b0e6c0ca884862f2","dc1bd44d2e0d47b0a023c9d58cdcb2db","b92d6325bf0b40178dee23088d3965d3","9b47a22f8e6a4a549d1195465283d267","2dc50033d01d4338ae6db70a48698e48"]},"outputId":"3837cf81-2073-4816-b402-41f13bd61fa9"},"execution_count":49,"outputs":[{"output_type":"stream","name":"stdout","text":["\n","    _|    _|  _|    _|    _|_|_|    _|_|_|  _|_|_|  _|      _|    _|_|_|      _|_|_|_|    _|_|      _|_|_|  _|_|_|_|\n","    _|    _|  _|    _|  _|        _|          _|    _|_|    _|  _|            _|        _|    _|  _|        _|\n","    _|_|_|_|  _|    _|  _|  _|_|  _|  _|_|    _|    _|  _|  _|  _|  _|_|      _|_|_|    _|_|_|_|  _|        _|_|_|\n","    _|    _|  _|    _|  _|    _|  _|    _|    _|    _|    _|_|  _|    _|      _|        _|    _|  _|        _|\n","    _|    _|    _|_|      _|_|_|    _|_|_|  _|_|_|  _|      _|    _|_|_|      _|        _|    _|    _|_|_|  _|_|_|_|\n","    \n","    To login, `huggingface_hub` requires a token generated from https://huggingface.co/settings/tokens .\n","Token: \n","Add token as git credential? (Y/n) n\n","Token is valid (permission: read).\n","Your token has been saved to /root/.cache/huggingface/token\n","Login successful\n"]},{"output_type":"display_data","data":{"text/plain":["Downloading (…)okenizer_config.json:   0%|          | 0.00/321 [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"3839d3805fbf42ad8f6eb808d367c538"}},"metadata":{}},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:1714: FutureWarning: The `use_auth_token` argument is deprecated and will be removed in v5 of Transformers.\n","  warnings.warn(\n"]},{"output_type":"display_data","data":{"text/plain":["Downloading (…)solve/main/vocab.txt:   0%|          | 0.00/232k [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"f9af4bb9ea0045018d2a48eb157db8a9"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["Downloading (…)/main/tokenizer.json:   0%|          | 0.00/466k [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"2d8c6eb4dbf74e67b86789ef2ed2c6be"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["Downloading (…)cial_tokens_map.json:   0%|          | 0.00/112 [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"4036595cbf2045b4894b442b05d05ee1"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["Downloading (…)lve/main/config.json:   0%|          | 0.00/639 [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"3e6e0ce2024c4381b7e0a893b99f02a6"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["Downloading pytorch_model.bin:   0%|          | 0.00/438M [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"88a1de725b8b49158cf6a865f4f0805a"}},"metadata":{}},{"output_type":"stream","name":"stderr","text":["Some weights of BertModel were not initialized from the model checkpoint at mental/mental-bert-base-uncased and are newly initialized: ['bert.pooler.dense.bias', 'bert.pooler.dense.weight']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"]}]},{"cell_type":"code","source":["test_size = 0.2\n","val_df = data.sample(frac=test_size, random_state=rand_state).reset_index (drop=True)\n","train_df = data.drop (val_df.index).reset_index (drop=True)\n","\n","\n","\n","train_dataset=CustomDataset(train_df, tokenizer, MAX_LEN)\n","valid_dataset=CustomDataset(val_df, tokenizer,MAX_LEN)\n","\n","train_data_loader = torch.utils.data.DataLoader (\n","train_dataset,\n","shuffle=True,\n","batch_size=TRAIN_BATCH_SIZE,\n","num_workers=0\n",")\n","val_data_loader = torch.utils.data.DataLoader (\n","valid_dataset,\n","shuffle=True,\n","batch_size=VALID_BATCH_SIZE,\n","num_workers=0\n",")"],"metadata":{"id":"_kXFUYmjZ2aT","executionInfo":{"status":"ok","timestamp":1690349438288,"user_tz":-330,"elapsed":408,"user":{"displayName":"Vedant Palit","userId":"05232341091904350034"}}},"execution_count":50,"outputs":[]},{"cell_type":"code","source":["def load_ckp(checkpoint_fpath, model, optimizer):\n","    \"\"\"\n","    checkpoint_path: path to save checkpoint\n","    model: model that we want to load checkpoint parameters into\n","    optimizer: optimizer we defined in previous training\n","    \"\"\"\n","    # load check point\n","    checkpoint = torch.load(checkpoint_fpath)\n","    # initialize state_dict from checkpoint to model\n","    model.load_state_dict(checkpoint['state_dict'])\n","    # initialize optimizer from checkpoint to optimizer\n","    optimizer.load_state_dict(checkpoint['optimizer'])\n","    # initialize valid_loss_min from checkpoint to valid_loss_min\n","    valid_loss_min = checkpoint['valid_loss_min']\n","    # return model, optimizer, epoch value, min validation loss\n","    return model, optimizer, checkpoint['epoch'], valid_loss_min.item()\n","\n","def save_ckp(state, is_best, checkpoint_path, best_model_path):\n","    \"\"\"\n","    state: checkpoint we want to save\n","    is_best: is this the best checkpoint; min validation loss\n","    checkpoint_path: path to save checkpoint\n","    best_model_path: path to save best model\n","    \"\"\"\n","    print(\"checkpoint_path:\",checkpoint_path)\n","    f_path = checkpoint_path\n","    # save checkpoint data to the path given, checkpoint_path\n","    torch.save(state, f_path)\n","    # if it is a best model, min validation loss\n","    if is_best:\n","        best_fpath = best_model_path\n","        # copy that checkpoint file to best path given, best_model_path\n","        shutil.copyfile(f_path, best_fpath)\n"],"metadata":{"id":"_nWQg1s2Z48j","executionInfo":{"status":"ok","timestamp":1690349439899,"user_tz":-330,"elapsed":1,"user":{"displayName":"Vedant Palit","userId":"05232341091904350034"}}},"execution_count":51,"outputs":[]},{"cell_type":"code","source":["def loss_fn(outputs, targets):\n","    return torch.nn.BCEWithLogitsLoss()(outputs, targets)"],"metadata":{"id":"fMuwnovWZ7Zl","executionInfo":{"status":"ok","timestamp":1690349442004,"user_tz":-330,"elapsed":2,"user":{"displayName":"Vedant Palit","userId":"05232341091904350034"}}},"execution_count":52,"outputs":[]},{"cell_type":"code","source":["optimizer = torch.optim.Adam(params =  model.parameters(), lr=LEARNING_RATE)\n","\n","\n","\n","val_targets=[]\n","val_outputs=[]"],"metadata":{"id":"DtGKWM2BZ9GK","executionInfo":{"status":"ok","timestamp":1690349443147,"user_tz":-330,"elapsed":649,"user":{"displayName":"Vedant Palit","userId":"05232341091904350034"}}},"execution_count":53,"outputs":[]},{"cell_type":"code","source":["\n","def train_model(n_epochs, training_loader, validation_loader, model,\n","                optimizer, checkpoint_path, best_model_path):\n","\n","  # initialize tracker for minimum validation loss\n","  valid_loss_min = np.Inf\n","\n","  for epoch in range(1, n_epochs+1):\n","    train_loss = 0\n","    valid_loss = 0\n","\n","    model.train()\n","\n","    for batch_idx, data in enumerate(training_loader):\n","        # print(data['input_ids'])\n","        ids = data['input_ids'].to(device, dtype = torch.long)\n","        # print(ids)\n","        # raise KeyboardInterrupt\n","        mask = data['attention_mask'].to(device, dtype = torch.long)\n","        token_type_ids = data['token_type_ids'].to(device, dtype = torch.long)\n","        targets = data['targets'].to(device, dtype = torch.float)\n","\n","        outputs, _ = model(ids, mask, token_type_ids)\n","\n","        optimizer.zero_grad()\n","        loss = loss_fn(outputs, targets)\n","\n","        # print(outputs)\n","        # loss2 = loss_fn2(outputs, targets)\n","\n","        # print(\"loss gambler: \",loss)\n","        # print(\"reservation: \", reservationn)\n","\n","        # print(\"loss2 CE: \", loss2)\n","\n","        # raise KeyboardInterrupt\n","        # tar, outp = loss_fn(outputs, targets.type(torch.int64))\n","        # return tar, outp\n","\n","        optimizer.zero_grad()\n","        loss.backward()\n","        optimizer.step()\n","        # print('before loss data in training', loss.item(), train_loss)\n","        train_loss = train_loss + ((1 / (batch_idx + 1)) * (loss.item() - train_loss))\n","        #print('after loss data in training', loss.item(), train_loss)\n","\n","    # print('############# Epoch {}: Training End     #############'.format(epoch))\n","\n","    # print('############# Epoch {}: Validation Start   #############'.format(epoch))\n","    ######################\n","    # validate the model #\n","    ######################\n","\n","    model.eval()\n","\n","    with torch.no_grad():\n","      for batch_idx, data in enumerate(validation_loader, 0):\n","            ids = data['input_ids'].to(device, dtype = torch.long)\n","            mask = data['attention_mask'].to(device, dtype = torch.long)\n","            token_type_ids = data['token_type_ids'].to(device, dtype = torch.long)\n","            targets = data['targets'].to(device, dtype = torch.float)\n","            outputs, _ = model(ids, mask, token_type_ids)\n","\n","            loss= loss_fn(outputs, targets)#.type(torch.int64)\n","            valid_loss = valid_loss + ((1 / (batch_idx + 1)) * (loss.item() - valid_loss))\n","            val_targets.extend(targets.cpu().detach().numpy().tolist())\n","            val_outputs.extend(torch.sigmoid(outputs).cpu().detach().numpy().tolist())\n","\n","      # print('############# Epoch {}: Validation End     #############'.format(epoch))\n","      # calculate average losses\n","      #print('before cal avg train loss', train_loss)\n","      train_loss = train_loss/len(training_loader)\n","      valid_loss = valid_loss/len(validation_loader)\n","      # print training/validation statistics\n","      print('Epoch: {} \\tAvgerage Training Loss: {:.6f} \\tAverage Validation Loss: {:.6f}'.format(\n","            epoch,\n","            train_loss,\n","            valid_loss\n","            ))\n","\n","      # create checkpoint variable and add important data\n","      checkpoint = {\n","            'epoch': epoch + 1,\n","            'valid_loss_min': valid_loss,\n","            'state_dict': model.state_dict(),\n","            'optimizer': optimizer.state_dict()\n","      }\n","        # save checkpoint\n","      # save_ckp(checkpoint, False, checkpoint_path, best_model_path)\n","\n","      ## TODO: save the model if validation loss has decreased\n","      if valid_loss <= valid_loss_min:\n","        print('Validation loss decreased ({:.6f} --> {:.6f}).  Saving model ...'.format(valid_loss_min,valid_loss))\n","        # save checkpoint as best model\n","        # save_ckp(checkpoint, True, checkpoint_path, best_model_path)\n","        valid_loss_min = valid_loss\n","\n","    # print('############# Epoch {}  Done   #############\\n'.format(epoch))\n","\n","  return model"],"metadata":{"id":"NAVVGDhDaBcz","executionInfo":{"status":"ok","timestamp":1690349443550,"user_tz":-330,"elapsed":2,"user":{"displayName":"Vedant Palit","userId":"05232341091904350034"}}},"execution_count":54,"outputs":[]},{"cell_type":"code","source":["import shutil, sys\n","\n","trained_model = train_model(EPOCHS, train_data_loader, val_data_loader, model, optimizer, \"ckpt_path/themodel3.pt\", \"thebestone3.pt\")"],"metadata":{"id":"MeGYXqfcaEFj","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1690349940278,"user_tz":-330,"elapsed":494023,"user":{"displayName":"Vedant Palit","userId":"05232341091904350034"}},"outputId":"b6efc47c-9bc8-4f67-fa8e-bf1141521ac6"},"execution_count":55,"outputs":[{"output_type":"stream","name":"stdout","text":["Epoch: 1 \tAvgerage Training Loss: 0.000364 \tAverage Validation Loss: 0.001185\n","Validation loss decreased (inf --> 0.001185).  Saving model ...\n","Epoch: 2 \tAvgerage Training Loss: 0.000287 \tAverage Validation Loss: 0.000966\n","Validation loss decreased (0.001185 --> 0.000966).  Saving model ...\n","Epoch: 3 \tAvgerage Training Loss: 0.000219 \tAverage Validation Loss: 0.000762\n","Validation loss decreased (0.000966 --> 0.000762).  Saving model ...\n","Epoch: 4 \tAvgerage Training Loss: 0.000146 \tAverage Validation Loss: 0.000712\n","Validation loss decreased (0.000762 --> 0.000712).  Saving model ...\n","Epoch: 5 \tAvgerage Training Loss: 0.000089 \tAverage Validation Loss: 0.000616\n","Validation loss decreased (0.000712 --> 0.000616).  Saving model ...\n"]}]},{"cell_type":"code","source":["last_layer_attentions = []\n","for batch_idx, data in enumerate(train_data_loader):\n","    ids = data['input_ids'].to(device, dtype=torch.long)\n","    mask = data['attention_mask'].to(device, dtype=torch.long)\n","    token_type_ids = data['token_type_ids'].to(device, dtype=torch.long)\n","    outputs, output_with_attention = trained_model(ids, mask, token_type_ids)\n","    #print(output_with_attention)\n","    if classifier_index == 0 or classifier_index==4:\n","        attentions = output_with_attention  # For XLNET and ERNIE\n","    else:\n","        attentions = output_with_attention.attentions[0]\n","\n","    for sample in attentions:\n","        last_layer_attentions.append((sample[11]).detach().cpu())  # Detach and move to CPU\n","\n","    # Clear GPU memory\n","    del ids, mask, token_type_ids, outputs, output_with_attention\n","    torch.cuda.empty_cache()"],"metadata":{"id":"WEpokgmfaJb_","executionInfo":{"status":"ok","timestamp":1690350527428,"user_tz":-330,"elapsed":25704,"user":{"displayName":"Vedant Palit","userId":"05232341091904350034"}}},"execution_count":56,"outputs":[]},{"cell_type":"code","execution_count":57,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"S64AP8ndqfsN","executionInfo":{"status":"ok","timestamp":1690350531761,"user_tz":-330,"elapsed":4357,"user":{"displayName":"Vedant Palit","userId":"05232341091904350034"}},"outputId":"ea021098-65b6-4aef-ca04-dbd365f1b62b"},"outputs":[{"output_type":"stream","name":"stdout","text":["***********************************\n","Model: Mental-BERT\n","Epochs: 5\n","Batch_size: 2\n","Max_len: 64\n","Learning Rate: 1e-05\n","Rand_state: 345\n","SVD_ranking : 45\n"]}],"source":["from numpy.linalg import svd\n","from numpy.linalg import matrix_rank\n","\n","d=[item.detach().numpy() for item in last_layer_attentions]\n","U, S, VT = svd(d)\n","print('***********************************')\n","print(\"Model:\", TheClassifier_Abstract)\n","print(\"Epochs:\", EPOCHS)\n","print(\"Batch_size:\",TRAIN_BATCH_SIZE)\n","print(\"Max_len:\", MAX_LEN)\n","print(\"Learning Rate:\", LEARNING_RATE)\n","print(\"Rand_state:\", rand_state)\n","print(\"SVD_ranking :\", matrix_rank(S))\n","\n","\n","# final_list=[]\n","# for i in val_df['Text']:\n","#   example = i\n","#   encodings = tokenizer.encode_plus(\n","#       example,\n","#       None,\n","#       add_special_tokens=True,\n","#       max_length=MAX_LEN,\n","#       padding='max_length',\n","#       return_token_type_ids=True,\n","#       truncation=True,\n","#       return_attention_mask=True,\n","#       return_tensors='pt'\n","#   )\n","#   model.eval()\n","#   with torch.no_grad():\n","#       input_ids = encodings['input_ids'].to(device, dtype=torch.long)\n","#       attention_mask = encodings['attention_mask'].to(device, dtype=torch.long)\n","#       token_type_ids = encodings['token_type_ids'].to(device, dtype=torch.long)\n","#       output, _ = model(input_ids, attention_mask, token_type_ids)\n","#       final_output = torch.sigmoid(output).cpu().detach().numpy().tolist()\n","#       # print(train_df.columns[1:].to_list()[int(np.argmax(final_output, axis=1))])\n","#       # final=[0 if i<0.4 else 1 for i in final_output[0]]\n","#       # print(\"final\",final)\n","#       final_list.append(final_output[0])\n","\n","# def finalLabels2(predicted_list,val_list):\n","\n","#   indices=np.array(predicted_list).argsort()[::-1][:int(sum(val_list))]\n","#   for j in range(len(predicted_list)):\n","#     if j in indices:\n","#       predicted_list[j]=1.0\n","#     else:\n","#       predicted_list[j]=0.0\n","#   return predicted_list\n","\n","\n","# def finalLabels(predicted_list,val_list):\n","#   for i in range(len(predicted_list)):\n","#     indices=np.array(predicted_list[i]).argsort()[::-1][:int(sum(val_list[i]))]\n","#     # argsort()[:-1][:n]\n","#     # print(predicted_list,np.array(predicted_list[i]).argsort()[::-1][:int(sum(val_list[i]))])\n","#     for j in range(len(predicted_list[i])):\n","#       if j in indices:\n","#         predicted_list[i][j]=1.0\n","#       else:\n","#         predicted_list[i][j]=0.0\n","#   return predicted_list\n","\n","\n","# final_list= []\n","# examples = []\n","# # for i in val_df['text']:\n","# #   example = i\n","# Final_Outputs = []\n","# for i in range(len(val_df)):\n","#   example  = val_df.loc[i]['Text']\n","#   target  = (val_df.loc[i][target_List]).tolist()\n","#   encodings = tokenizer.encode_plus(\n","#       example,\n","#       None,\n","#       add_special_tokens=True,\n","#       max_length=MAX_LEN,\n","#       padding='max_length',\n","#       return_token_type_ids=True,\n","#       truncation=True,\n","#       return_attention_mask=True,\n","#       return_tensors='pt'\n","#   )\n","#   model.eval()\n","#   with torch.no_grad():\n","#       input_ids = encodings['input_ids'].to(device, dtype=torch.long)\n","#       attention_mask = encodings['attention_mask'].to(device, dtype=torch.long)\n","#       token_type_ids = encodings['token_type_ids'].to(device, dtype=torch.long)\n","#       output, _ = model(input_ids, attention_mask, token_type_ids)\n","#       temp = torch.Tensor(target).type(torch.int64).to(device)\n","#       loss, reservation = loss_fn(output,temp.reshape([1,dimension]))\n","#       final_output = torch.sigmoid(output).cpu().detach().numpy().tolist()\n","#       # print(train_df.columns[1:].to_list()[int(np.argmax(final_output, axis=1))])\n","#       # final=[0 if i<0.4 else 1 for i in final_output[0]]\n","#       # print(\"final\",final)\n","#       # print(final_output[0][:-1], target)\n","#       temp = finalLabels2(final_output[0][:-1],target)\n","#       # print(temp)\n","\n","#       # raise KeyInterruption\n","#       # print(\"tepm: \",temp)\n","#       # print(\"target:\", target.tolist())\n","#       # print(\"All: \", temp+target+torch.Tensor.tolist(reservation))\n","\n","#       final_list.append(temp+target+torch.Tensor.tolist(reservation))\n","#       examples.append(example)\n","#       Final_Outputs.append({'text':example,'target':target, 'output':temp, 'reservation':reservation})\n","#       # record\n","\n","\n","\n","# from operator import itemgetter\n","# Final_Outputs.sort(key=itemgetter('reservation'),reverse = False)\n","# # print(dimension,2*dimension-1)\n","# # print(\"final first cell:\", final_list[0])\n","\n","# sorted_final_list = sorted(final_list, key=itemgetter(2*dimension - 1), reverse = False)\n","# # print(sorted_final_list)\n","# # print(Final_Outputs[:2])\n","# # import pickle\n","# # with open(\"Final_Outputs\", \"wb\") as fp:\n","# #   pickle.dump(Final_Outputs, fp)\n","\n","# # with open(\"Final_Outputs\", \"rb\") as fp:\n","# #   Final_Outputs = pickle.load(fp)\n","\n","# from sklearn.metrics import multilabel_confusion_matrix\n","\n","# def get_accuracies(true_labels, predictions):\n","#     #https://scikit-learn.org/stable/modules/generated/sklearn.metrics.multilabel_confusion_matrix.html\n","#     cm = multilabel_confusion_matrix(true_labels, predictions)\n","#     total_count = np.array(true_labels).shape[0]\n","#     accuracies = []\n","#     for i in range(np.array(true_labels).shape[1]):\n","#         true_positive_count = np.sum(cm[i,1,1]).item()\n","#         true_negative_count = np.sum(cm[i,0,0]).item()\n","#         accuracy = (true_positive_count + true_negative_count) / total_count\n","#         accuracies.append(accuracy)\n","#     return accuracies\n","\n","\n","\n","\n","# from sklearn.metrics import classification_report\n","# from sklearn.metrics import matthews_corrcoef\n","# # import tensorflow_addons as tfa\n","\n","# label_names = target_List\n","# for threshold in [1, 0.95, .9, 0.85, 0.8, .75]: #,\n","#   list_data = sorted_final_list[round(threshold*len(sorted_final_list)-1):]\n","#   list_data = sorted_final_list[:round(threshold*len(sorted_final_list)-1)]\n","#   val_list = [list_data[i][4:8] for i in range(len(list_data))]\n","#   prediction = [list_data[i][0:4] for i in range(len(list_data))]\n","#   print('############# '+TheClassifier_Abstract+'_'+str(rand_state)+'_'+str(threshold)+'   #############')\n","\n","#   #  print(\"val_list\",val_list[0:5])\n","#   #  print(\"prediction\", prediction[0:5])\n","#   #  print(\"label_names\", label_names)\n","#   print(classification_report(np.argmax(val_list, axis=1), np.argmax(prediction, axis=1), target_names=label_names))\n","#   accuracies = get_accuracies(val_list,prediction)\n","#   accuracy_average = sum(accuracies)/dimension\n","#   accuracies = [round(accuracies[i],2) for i in range(dimension)]\n","\n","#   print(\"accuracies for each class:\",accuracies, \"Average:\", accuracy_average)\n","\n","#   # print(len(val_list), val_list[0])\n","#   # print(len(prediction), prediction[0])\n","\n","\n","#   val = pd.DataFrame(val_list, columns = target_List)\n","#   fin = pd.DataFrame(prediction, columns = target_List)\n","\n","#   print(\"MCC [Aspect1, Aspect2, Aspect3, Aspect4]\", matthews_corrcoef(val[\"Aspect1\"],fin[\"Aspect1\"]), matthews_corrcoef(val[\"Aspect2\"],fin[\"Aspect2\"]), matthews_corrcoef(val[\"Aspect3\"],fin[\"Aspect3\"]), matthews_corrcoef(val[\"Aspect4\"],fin[\"Aspect4\"]))"]}]}