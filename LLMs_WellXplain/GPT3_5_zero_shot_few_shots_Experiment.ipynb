{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "C-WFyMtVrGWs"
      },
      "source": [
        "***Important notes***:\n",
        "\n",
        "Before any running please upload WellXplain.csv in the session storage. To do so, you can use the Files section in the left side of this page.\n",
        "\n",
        "Create the path in the path variable in the first cell. Or you can create your own path for saving results.\n",
        "\n",
        "You also need API key for access to GPT 4 API which would need payment. You need to insert your key into the appropariate places where it mention openai.api_key=\"your key.\"\n",
        "\n",
        "In the very few cells, we used append() function to append samples extracted from each class to gether. If it won't work you should use concat() function."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "n1VfUI7c7e7t"
      },
      "source": [
        "# Requirements and Data preparation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "kpOpS0uyqZmH"
      },
      "outputs": [],
      "source": [
        "path =\"/content/drive/MyDrive/ACL_code/results/GPT3.5/\" # the path for saving results"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ttopyCJccZx4",
        "outputId": "bd001c95-2b3a-412a-c230-18c441539796"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "<ipython-input-2-d05506e76d3e>:1: TqdmExperimentalWarning: Using `tqdm.autonotebook.tqdm` in notebook mode. Use `tqdm.tqdm` instead to force console mode (e.g. in jupyter console)\n",
            "  from tqdm.autonotebook import tqdm\n"
          ]
        }
      ],
      "source": [
        "from tqdm.autonotebook import tqdm"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "TwCQT6vy47XC"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import pickle"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "UjWVfNApvZdk"
      },
      "outputs": [],
      "source": [
        "# reading data\n",
        "import pandas as pd\n",
        "data = pd.read_csv('WellXplain.csv',index_col=0)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "14t85QdWyR32"
      },
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "QdSZLhLAV0DS"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "def convert_to_one_hot(input_vector):\n",
        "  input_vector_array = np.array(input_vector)\n",
        "  input_vector_one_hot = np.zeros((input_vector_array.size, 4))\n",
        "  input_vector_one_hot[np.arange(input_vector_array.size), input_vector_array-1] = 1\n",
        "  return input_vector_one_hot"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "chxiO_Dv03lX"
      },
      "source": [
        "# gpt 3.5 zero shot and few shots"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "41cJLHVS1CqE",
        "outputId": "dbfea783-7464-4353-facc-c05bd51e440a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m325.5/325.5 kB\u001b[0m \u001b[31m11.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m75.6/75.6 kB\u001b[0m \u001b[31m11.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m77.9/77.9 kB\u001b[0m \u001b[31m10.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m58.3/58.3 kB\u001b[0m \u001b[31m8.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ],
      "source": [
        "!pip install openai --quiet\n",
        "# !pip install openai"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "SJ7oEOLB2gvu"
      },
      "outputs": [],
      "source": [
        "import base64\n",
        "import requests\n",
        "import re\n",
        "import openai\n",
        "from openai import OpenAI\n",
        "import json\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "E_tDAxMI2rUE"
      },
      "outputs": [],
      "source": [
        "model = \"gpt-3.5-turbo\"\n",
        "\n",
        "def generate_message(data, formatted_prompt):\n",
        "  messages = [{\"role\": \"system\", \"content\": \"You are a helpful assistant who can classify wellness dimensions/aspects and provide parts of the input you mostly consider for your decision.\"}]\n",
        "  # print(len(data))\n",
        "  for i in range(len(data)):\n",
        "    messages.append({\"role\": \"user\", \"content\": data.iloc[i]['Text']})\n",
        "    messages.append({\"role\": \"assistant\", \"content\": \"label:\"+str(data.iloc[i]['Aspect'])+\"\\n explanation:\"+data.iloc[i]['Explanations']})\n",
        "  messages.append({\"role\": \"user\", \"content\": formatted_prompt})\n",
        "  return messages\n",
        "\n",
        "def gpt_explanation_prediction(post, model=model):\n",
        "    # client = OpenAI(api_key=os.environ[\"sk-your key\"])\n",
        "    client = openai\n",
        "    openai.api_key =\"sk-...\" # Please insert your api key for gpt 4 here\n",
        "\n",
        "    prediction = 0\n",
        "    explanation=\"\"\n",
        "\n",
        "\n",
        "    # The \"simple\" here is intentional: I tried multiple variants: awesome, nice, cool.\n",
        "    # but starting with simple and refining leads to the lower error rates.\n",
        "    prompt = f\"\"\"\n",
        "    First, understand the following definitions:\n",
        "    Physical Aspect (PA): Physical wellness fosters healthy dietary practices while discouraging harmful behaviors like tobacco use, drug misuse, and excessive alcohol consumption. Achieving optimal physical wellness involves regular physical activity, sufficient sleep, vitality, enthusiasm, and beneficial eating habits. Body shaming can negatively affect physical well-being by increasing awareness of medical history and appearance issues.\n",
        "    Intellectual Aspect (IA): Utilizing intellectual and cultural activities, both inside and outside the classroom, and leveraging human and learning resources enhance the wellness of an individual by nurturing intellectual growth and stimulation.\n",
        "    Vocational Aspect (VA): The Vocational Dimension acknowledges the role of personal gratification and enrichment derived from one's occupation in shaping life satisfaction. It influences an individual's perspective on creative problem-solving, professional development, and the management of financial obligations.\n",
        "    Social Aspect (SA): The Social Dimension highlights the interplay between society and the natural environment, increasing individuals' awareness of their role in society and their impact on ecosystems. Social bonds enhance interpersonal traits, enabling a better understanding and appreciation of cultural influences.\n",
        "    Spiritual Aspect (SpA): The Spiritual Dimension involves seeking the meaning and purpose of human life, appreciating its vastness and natural forces, and achieving harmony within oneself.\n",
        "    Emotional Aspect (EA): The Emotional Dimension enhances self-awareness and positivity, promoting better emotional control, realistic self-appraisal, independence, and effective stress management.\n",
        "\n",
        "\n",
        "    Now, you will be given a textual post. Classify the post into one of these labels: 1, 2, 3, or 4.\n",
        "    If the post is physical aspect, return 1; if it is either intellectual or vocational aspect, or both of these aspects, return 2;\n",
        "    if the post is social aspect, return 3; and if the post is either spiritual or emotional, or both of these aspect, return 4.\n",
        "    After that, just list (in order based on the importance) at most four parts of the post were the most important parts you considered to make your decision.\n",
        "    You should provide your output as a python list with two values the first one represents your prediction (1, 2, 3, or 4) and\n",
        "    the second one represents the parts you consider the most important parts used for your prediction, like the following:\n",
        "    [value1, value2]\n",
        "\n",
        "    Textual post: {post}\n",
        "\n",
        "\n",
        "    \"\"\"\n",
        "    formatted_prompt = prompt.format(post=post)\n",
        "\n",
        "    messages = generate_message(train, formatted_prompt)\n",
        "    # print(messages)\n",
        "\n",
        "    response = client.chat.completions.create(\n",
        "        model=model,\n",
        "        messages=[\n",
        "            {\"role\": \"system\", \"content\": \"You are a helpful assistant who can classify wellness aspects and provide parts of the post that you consider to make your prediction based on them.\"},\n",
        "            {\"role\": \"user\", \"content\": formatted_prompt},\n",
        "        ]\n",
        "    )\n",
        "    return response\n",
        "\n",
        "def extract_explanation_from_response(response):\n",
        "    # Check if the response is a dictionary and has the 'choices' key\n",
        "    if isinstance(response, openai.types.chat.chat_completion.ChatCompletion):\n",
        "      content = response.choices[0].message.content\n",
        "    elif isinstance(response, dict) and 'choices' in response:\n",
        "      content = response['choices'][0]['message']['content']\n",
        "    elif isinstance(response, str) and isinstance(json.loads(response), dict) and 'choices' in json.loads(response):\n",
        "      content = json.loads(response)['choices'][0]['message']['content']\n",
        "    else:\n",
        "      print(\"Invalid response format.\")\n",
        "      return None\n",
        "    extracted_response=content.split(\"\\n\")\n",
        "    return extracted_response[0], extracted_response[1]\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "5Ce5zxihPNWo"
      },
      "outputs": [],
      "source": [
        "def few_shots_preparing(number_prompt_sample):\n",
        "  label1 = data[data[\"Aspect\"]==1].sample(n=number_prompt_sample, replace=False, random_state = random_state)\n",
        "  label2 = data[data[\"Aspect\"]==2].sample(n=number_prompt_sample, replace=False, random_state = random_state)\n",
        "  label3 = data[data[\"Aspect\"]==3].sample(n=number_prompt_sample, replace=False, random_state = random_state)\n",
        "  label4 = data[data[\"Aspect\"]==4].sample(n=number_prompt_sample, replace=False, random_state = random_state)\n",
        "\n",
        "  data_balanced = label1\n",
        "  data_balanced = data_balanced._append(label2)\n",
        "  data_balanced = data_balanced._append(label3)\n",
        "  data_balanced = data_balanced._append(label4)\n",
        "  # data_balanced.columns=[\"index\",\"Text\",\"Aspect\",\"Explanations\"]\n",
        "\n",
        "  return data_balanced"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "8ZregTp2SET5"
      },
      "outputs": [],
      "source": [
        "def validation_data(number_validation_sample, train):\n",
        "  data1 = data.drop(train.index)\n",
        "  return data1\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "collapsed": true,
        "id": "DRbBeZgF_IWf"
      },
      "outputs": [],
      "source": [
        "def main(file_name,val_data):\n",
        "  results = []\n",
        "  if os.path.isfile(file_name):\n",
        "    with open(file_name, 'rb') as f:\n",
        "      results = pickle.load(f)\n",
        "\n",
        "  for i in tqdm(range(len(val_data))):\n",
        "\n",
        "    output = gpt_explanation_prediction(val_data.iloc[i]['Text'])\n",
        "    content = output.choices[0].message.content\n",
        "\n",
        "    results.append([val_data.iloc[i]['tmp'], val_data.iloc[i]['Text'],val_data.iloc[i]['Aspect'],val_data.iloc[i]['Explanations'], content])\n",
        "    if i%30 ==0:\n",
        "      with open(file_name, 'wb') as f:\n",
        "        pickle.dump(results, f)\n",
        "  with open(file_name, 'wb') as f:\n",
        "        pickle.dump(results, f)\n",
        "\n",
        "  return results\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "6t5M_GImV7dc"
      },
      "outputs": [],
      "source": [
        "def retreive_results(file_name):\n",
        "  with open(file_name, 'rb') as f:\n",
        "      results = pickle.load(f)\n",
        "  manual_checking = []\n",
        "  true_label = []\n",
        "  prediction= []\n",
        "  # for i in range(len(results)):\n",
        "  for itr, item in enumerate(results):\n",
        "    try:\n",
        "      output = eval(item[4])\n",
        "      true_label.append(item[2])\n",
        "      prediction.append(output[0])\n",
        "    except:\n",
        "      manual_checking.append(itr)\n",
        "      continue\n",
        "  return true_label, prediction"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fe3MT-5NWkuX",
        "outputId": "3d58650e-9530-4d72-8b80-aa81c5353e55"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting tensorflow_addons\n",
            "  Downloading tensorflow_addons-0.23.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (611 kB)\n",
            "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/611.8 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[91m━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m327.7/611.8 kB\u001b[0m \u001b[31m9.6 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m611.8/611.8 kB\u001b[0m \u001b[31m12.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from tensorflow_addons) (24.1)\n",
            "Collecting typeguard<3.0.0,>=2.7 (from tensorflow_addons)\n",
            "  Downloading typeguard-2.13.3-py3-none-any.whl (17 kB)\n",
            "Installing collected packages: typeguard, tensorflow_addons\n",
            "Successfully installed tensorflow_addons-0.23.0 typeguard-2.13.3\n"
          ]
        }
      ],
      "source": [
        "pip install tensorflow_addons"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WjOJdAcpWQq7",
        "outputId": "15966f03-7fdc-43e4-f5e9-2f5dd670e1c2"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/tensorflow_addons/utils/tfa_eol_msg.py:23: UserWarning: \n",
            "\n",
            "TensorFlow Addons (TFA) has ended development and introduction of new features.\n",
            "TFA has entered a minimal maintenance and release mode until a planned end of life in May 2024.\n",
            "Please modify downstream libraries to take dependencies from other repositories in our TensorFlow community (e.g. Keras, Keras-CV, and Keras-NLP). \n",
            "\n",
            "For more information see: https://github.com/tensorflow/addons/issues/2807 \n",
            "\n",
            "  warnings.warn(\n"
          ]
        }
      ],
      "source": [
        "import tensorflow_addons as tfa\n",
        "from sklearn.metrics import matthews_corrcoef\n",
        "from sklearn.metrics import classification_report\n",
        "def metrics():\n",
        "  target_List =[\"Aspect1\",\"Aspect2\",\"Aspect3\",\"Aspect4\"]\n",
        "  print(classification_report(true_label, prediction, labels =np.array(range(1, len(target_List)+1)),target_names=target_List, digits=4,zero_division=0))\n",
        "\n",
        "  metric = tfa.metrics.MatthewsCorrelationCoefficient(num_classes=4)\n",
        "  metric.update_state(true_label_one_hot,prediction_one_hot)\n",
        "  result = metric.result()\n",
        "  print(result.numpy())\n",
        "  print('target_List:', target_List)\n",
        "\n",
        "  val = pd.DataFrame(true_label_one_hot, columns = target_List)\n",
        "  fin = pd.DataFrame(prediction_one_hot, columns = target_List)\n",
        "\n",
        "  from sklearn.metrics import matthews_corrcoef\n",
        "  print(matthews_corrcoef(val[\"Aspect1\"],fin[\"Aspect1\"]))\n",
        "\n",
        "  from sklearn.metrics import matthews_corrcoef\n",
        "  print(matthews_corrcoef(val[\"Aspect2\"],fin[\"Aspect2\"]))\n",
        "\n",
        "  from sklearn.metrics import matthews_corrcoef\n",
        "  print(matthews_corrcoef(val[\"Aspect3\"],fin[\"Aspect3\"]))\n",
        "\n",
        "  from sklearn.metrics import matthews_corrcoef\n",
        "  print(matthews_corrcoef(val[\"Aspect4\"],fin[\"Aspect4\"]))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "f2VcBGKBpsPf"
      },
      "outputs": [],
      "source": [
        "def calculate_acc(results):\n",
        "  c = 0\n",
        "  manual_checking = []\n",
        "  # for i in range(len(results)):\n",
        "  for iter, item in enumerate(results):\n",
        "    i = item[0]\n",
        "    try:\n",
        "      output = eval(item[4])\n",
        "    except:\n",
        "      manual_checking.append(iter)\n",
        "      continue\n",
        "    # print(item[2], output[0])\n",
        "    if item[2]==output[0]:\n",
        "      c+=1\n",
        "  return c/(len(results)-len(manual_checking))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "IOsA9FgqfEu5"
      },
      "outputs": [],
      "source": [
        "random_state = 42"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "TQkh6_5rO5DJ"
      },
      "outputs": [],
      "source": [
        "# Few-Shots, 5 shots per class\n",
        "\n",
        "number_prompt_sample = 5 # number of shots for each class\n",
        "number_validation_sample = 100 # number of test samples\n",
        "file_name =path+\"gpt35_few_shots_5.pkl\"\n",
        "\n",
        "# reading data\n",
        "import pandas as pd\n",
        "data = pd.read_csv('WellXplain.csv',index_col=0)\n",
        "\n",
        "train =few_shots_preparing(number_prompt_sample)\n",
        "val_data = validation_data(number_validation_sample, train)\n",
        "val_data['tmp'] =val_data.index\n",
        "\n",
        "results = main(file_name = file_name, val_data=val_data)\n",
        "true_label, prediction = retreive_results(file_name)\n",
        "true_label_one_hot = convert_to_one_hot(true_label)\n",
        "prediction_one_hot = convert_to_one_hot(prediction)\n",
        "\n",
        "metrics()\n",
        "print(\"Accuracy:\", calculate_acc(results))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "TxdAXk9WS4sJ"
      },
      "outputs": [],
      "source": [
        "# Few-Shots, 10 shots per class\n",
        "\n",
        "number_prompt_sample = 10 # number of shots for each class\n",
        "number_validation_sample = 100 # number of test samples\n",
        "file_name =path+\"gpt35_few_shots_10.pkl\"\n",
        "\n",
        "# reading data\n",
        "import pandas as pd\n",
        "data = pd.read_csv('WellXplain.csv',index_col=0)\n",
        "\n",
        "train =few_shots_preparing(number_prompt_sample)\n",
        "val_data = validation_data(number_validation_sample, train)\n",
        "val_data['tmp'] =val_data.index\n",
        "\n",
        "results = main(file_name = file_name, val_data=val_data)\n",
        "true_label, prediction = retreive_results(file_name)\n",
        "true_label_one_hot = convert_to_one_hot(true_label)\n",
        "prediction_one_hot = convert_to_one_hot(prediction)\n",
        "\n",
        "metrics()\n",
        "print(\"Accuracy:\", calculate_acc(results))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 416,
          "referenced_widgets": [
            "a40c18bf28db401791e1b1478236f0a2",
            "f0bb6475f66d4d67a44f79d68af7a892",
            "9419b75191564aedac66883409f8da9e",
            "a3da2bc350d744fc8b51b7264e5302fe",
            "75a15c322273467b81821e79a9045e56",
            "8d84b87870c8428e8c1e01858f36fbb4",
            "49058e0139e8456baf5187423e6249ae",
            "e063b49ca6ba46acb89d41bc51fdee75",
            "091a0478d287452e96ebaf21b33e0a1b",
            "9167a16ddd9a41c4bfc70cf438f6cf25",
            "5ce6440722234377924a5c32b602754b"
          ]
        },
        "id": "PyJTj_DJUp4x",
        "outputId": "70cdae1e-2179-480b-bf57-fd4dde926466"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "a40c18bf28db401791e1b1478236f0a2",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "  0%|          | 0/3092 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "     Aspect1     0.8145    0.2049    0.3274       493\n",
            "     Aspect2     0.8402    0.4256    0.5650       383\n",
            "     Aspect3     0.8369    0.1667    0.2780       708\n",
            "     Aspect4     0.2467    0.9424    0.3911       399\n",
            "\n",
            "    accuracy                         0.3822      1983\n",
            "   macro avg     0.6846    0.4349    0.3904      1983\n",
            "weighted avg     0.7132    0.3822    0.3684      1983\n",
            "\n",
            "0.31349567\n",
            "target_List: ['Aspect1', 'Aspect2', 'Aspect3', 'Aspect4']\n",
            "0.3381576372798971\n",
            "0.539767325912764\n",
            "0.27708714731650147\n",
            "0.20684303228693196\n",
            "Accuracy: 0.3822491174987393\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "<string>:1: SyntaxWarning: list indices must be integers or slices, not str; perhaps you missed a comma?\n",
            "<string>:1: SyntaxWarning: list indices must be integers or slices, not str; perhaps you missed a comma?\n"
          ]
        }
      ],
      "source": [
        "# Zero-Shots, 0 shots per class\n",
        "\n",
        "number_prompt_sample = 0 # number of shots for each class\n",
        "number_validation_sample = 100 # number of test samples\n",
        "file_name =path+\"gpt35_zero_shots.pkl\"\n",
        "\n",
        "# reading data\n",
        "import pandas as pd\n",
        "data = pd.read_csv('WellXplain.csv',index_col=0)\n",
        "\n",
        "train =few_shots_preparing(number_prompt_sample)\n",
        "val_data = validation_data(number_validation_sample, train)\n",
        "val_data['tmp'] =val_data.index\n",
        "\n",
        "results = main(file_name = file_name, val_data=val_data)\n",
        "true_label, prediction = retreive_results(file_name)\n",
        "true_label_one_hot = convert_to_one_hot(true_label)\n",
        "prediction_one_hot = convert_to_one_hot(prediction)\n",
        "\n",
        "metrics()\n",
        "print(\"Accuracy:\", calculate_acc(results))"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "A100",
      "machine_shape": "hm",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "091a0478d287452e96ebaf21b33e0a1b": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "49058e0139e8456baf5187423e6249ae": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "5ce6440722234377924a5c32b602754b": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "75a15c322273467b81821e79a9045e56": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "8d84b87870c8428e8c1e01858f36fbb4": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "9167a16ddd9a41c4bfc70cf438f6cf25": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "9419b75191564aedac66883409f8da9e": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_e063b49ca6ba46acb89d41bc51fdee75",
            "max": 3092,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_091a0478d287452e96ebaf21b33e0a1b",
            "value": 3092
          }
        },
        "a3da2bc350d744fc8b51b7264e5302fe": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_9167a16ddd9a41c4bfc70cf438f6cf25",
            "placeholder": "​",
            "style": "IPY_MODEL_5ce6440722234377924a5c32b602754b",
            "value": " 3092/3092 [47:22&lt;00:00,  1.14it/s]"
          }
        },
        "a40c18bf28db401791e1b1478236f0a2": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_f0bb6475f66d4d67a44f79d68af7a892",
              "IPY_MODEL_9419b75191564aedac66883409f8da9e",
              "IPY_MODEL_a3da2bc350d744fc8b51b7264e5302fe"
            ],
            "layout": "IPY_MODEL_75a15c322273467b81821e79a9045e56"
          }
        },
        "e063b49ca6ba46acb89d41bc51fdee75": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f0bb6475f66d4d67a44f79d68af7a892": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_8d84b87870c8428e8c1e01858f36fbb4",
            "placeholder": "​",
            "style": "IPY_MODEL_49058e0139e8456baf5187423e6249ae",
            "value": "100%"
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
